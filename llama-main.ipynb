{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "#from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "#from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "# def read_data(input_dir, num_workers=4):\n",
    "#     reader = SimpleDirectoryReader(input_dir=input_dir)\n",
    "#     documents = reader.load_data()\n",
    "#     return documents\n",
    "\n",
    "# def build_index(documents):\n",
    "#     # create the pipeline with transformations\n",
    "#     #embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "#     embed_model = OpenAIEmbedding()\n",
    "#     #index = VectorStoreIndex.from_documents(documents=documents, transformations=[embed_model])\n",
    "#     pipeline = IngestionPipeline(\n",
    "#         transformations=[\n",
    "#             #SentenceSplitter(chunk_size=25, chunk_overlap=0),\n",
    "#             #TitleExtractor(),\n",
    "#             #OpenAIEmbedding(),\n",
    "#             embed_model\n",
    "#         ],\n",
    "#     )\n",
    "    \n",
    "#     nodes = pipeline.run(documents=documents)\n",
    "#     index = VectorStoreIndex(nodes, embed_model=embed_model)\n",
    "\n",
    "#     return index\n",
    "\n",
    "\n",
    "# def save_emb(documents, persist_dir):\n",
    "#     index = build_index(documents)\n",
    "    \n",
    "#     storage_context = StorageContext.from_defaults(\n",
    "#         docstore=SimpleDocumentStore(),\n",
    "#         vector_store=SimpleVectorStore(),\n",
    "#         index_store=SimpleIndexStore(),\n",
    "#     )\n",
    "#     index.storage_context.persist(persist_dir=persist_dir)\n",
    "\n",
    "# def load_emb_index(self, persist_dir):\n",
    "#     # storage_context = StorageContext.from_defaults(\n",
    "#     #     docstore=SimpleDocumentStore.from_persist_dir(persist_dir=persist_dir),\n",
    "#     #     vector_store=SimpleVectorStore.from_persist_dir(persist_dir=persist_dir),\n",
    "#     #     index_store=SimpleIndexStore.from_persist_dir(persist_dir=persist_dir)\n",
    "#     # )\n",
    "#     index_store=SimpleIndexStore.from_persist_dir(persist_dir=persist_dir)\n",
    "#     return index_store\n",
    "    \n",
    "\n",
    "# async def build_agent_per_doc(nodes, file_base):\n",
    "#     print(file_base)\n",
    "\n",
    "#     vi_out_path = f\"./data/llamaindex_docs/{file_base}\"\n",
    "#     summary_out_path = f\"./data/llamaindex_docs/{file_base}_summary.pkl\"\n",
    "#     if not os.path.exists(vi_out_path):\n",
    "#         Path(\"./data/llamaindex_docs/\").mkdir(parents=True, exist_ok=True)\n",
    "#         # build vector index\n",
    "#         vector_index = VectorStoreIndex(nodes)\n",
    "#         vector_index.storage_context.persist(persist_dir=vi_out_path)\n",
    "#     else:\n",
    "#         vector_index = load_index_from_storage(\n",
    "#             StorageContext.from_defaults(persist_dir=vi_out_path),\n",
    "#         )\n",
    "\n",
    "#     # build summary index\n",
    "#     summary_index = SummaryIndex(nodes)\n",
    "\n",
    "#     # define query engines\n",
    "#     vector_query_engine = vector_index.as_query_engine(llm=llm)\n",
    "#     summary_query_engine = summary_index.as_query_engine(\n",
    "#         response_mode=\"tree_summarize\", llm=llm\n",
    "#     )\n",
    "\n",
    "#     # extract a summary\n",
    "#     if not os.path.exists(summary_out_path):\n",
    "#         Path(summary_out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "#         summary = str(\n",
    "#             await summary_query_engine.aquery(\n",
    "#                 \"Extract a concise 1-2 line summary of this document\"\n",
    "#             )\n",
    "#         )\n",
    "#         pickle.dump(summary, open(summary_out_path, \"wb\"))\n",
    "#     else:\n",
    "#         summary = pickle.load(open(summary_out_path, \"rb\"))\n",
    "\n",
    "#     # define tools\n",
    "#     query_engine_tools = [\n",
    "#         QueryEngineTool(\n",
    "#             query_engine=vector_query_engine,\n",
    "#             metadata=ToolMetadata(\n",
    "#                 name=f\"vector_tool_{file_base}\",\n",
    "#                 description=f\"Useful for questions related to specific facts\",\n",
    "#             ),\n",
    "#         ),\n",
    "#         QueryEngineTool(\n",
    "#             query_engine=summary_query_engine,\n",
    "#             metadata=ToolMetadata(\n",
    "#                 name=f\"summary_tool_{file_base}\",\n",
    "#                 description=f\"Useful for summarization questions\",\n",
    "#             ),\n",
    "#         ),\n",
    "#     ]\n",
    "\n",
    "#     # build agent\n",
    "#     function_llm = OpenAI(model=\"gpt-4\")\n",
    "#     agent = OpenAIAgent.from_tools(\n",
    "#         query_engine_tools,\n",
    "#         llm=function_llm,\n",
    "#         verbose=True,\n",
    "#         system_prompt=f\"\"\"\\\n",
    "# You are a specialized agent designed to answer queries about the `{file_base}.html` part of the LlamaIndex docs.\n",
    "# You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
    "# \"\"\",\n",
    "#     )\n",
    "\n",
    "#     return agent, summary\n",
    "\n",
    "\n",
    "# async def build_agents(docs):\n",
    "#     node_parser = SentenceSplitter()\n",
    "\n",
    "#     # Build agents dictionary\n",
    "#     agents_dict = {}\n",
    "#     extra_info_dict = {}\n",
    "\n",
    "#     # # this is for the baseline\n",
    "#     # all_nodes = []\n",
    "\n",
    "#     for idx, doc in enumerate(tqdm(docs)):\n",
    "#         nodes = node_parser.get_nodes_from_documents([doc])\n",
    "#         # all_nodes.extend(nodes)\n",
    "\n",
    "#         # ID will be base + parent\n",
    "#         file_path = Path(doc.metadata[\"path\"])\n",
    "#         file_base = str(file_path.parent.stem) + \"_\" + str(file_path.stem)\n",
    "#         agent, summary = await build_agent_per_doc(nodes, file_base)\n",
    "\n",
    "#         agents_dict[file_base] = agent\n",
    "#         extra_info_dict[file_base] = {\"summary\": summary, \"nodes\": nodes}\n",
    "\n",
    "#     return agents_dict, extra_info_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(path):\n",
    "    # Walk through all files in the given path and return a list of documents\n",
    "    documents = []\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        all_files.append(files)\n",
    "        for file in files:\n",
    "            document_path = os.path.join(root, file)\n",
    "            documents.append(SimpleDirectoryReader(input_files=[document_path]).load_data())\n",
    "            \n",
    "\n",
    "    indexes = []\n",
    "    for i in documents:\n",
    "        indexes.append(VectorStoreIndex.from_documents(documents=i))\n",
    "        \n",
    "    return indexes, files\n",
    "\n",
    "# def create_engines_tools(indexes):\n",
    "#     query_engine_tools = [\n",
    "#     QueryEngineTool(\n",
    "#         query_engine=index.as_query_engine(similarity_top_k=3),\n",
    "#         metadata=ToolMetadata(\n",
    "#             name=f\"engine_{i}\",\n",
    "#             description=\"Provides information from the car data. \"\n",
    "#                         \"Use a detailed plain text question as input to the tool.\"\n",
    "#         ),\n",
    "#     ) for i, index in enumerate(indexes)\n",
    "#     ]\n",
    "#     return query_engine_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/customer data - preffered car price.csv with error: 'utf-8' codec can't decode byte 0xc5 in position 8694: invalid continuation byte. Skipping...\n"
     ]
    }
   ],
   "source": [
    "indexes, files = read_folder('data/')\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "#print(files)\n",
    "\n",
    "#tools = create_engines_tools(indexes)\n",
    "\n",
    "tools = [QueryEngineTool.from_defaults(\n",
    "    indexes[i].as_query_engine(), name=f\"engine_{i}\", description=f\"Provides information about {files[i]}\"\n",
    ") for i in range(len(indexes))]\n",
    "\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call: Customer with args: {\n",
      "  \"Name\": \"Sarah\",\n",
      "  \"Type\": \"\",\n",
      "  \"Country\": \"\",\n",
      "  \"Age\": \"\",\n",
      "  \"AgeGroupWithSignificance\": \"\",\n",
      "  \"Gender\": \"\",\n",
      "  \"IncomeLevel\": \"\",\n",
      "  \"Residence\": \"\",\n",
      "  \"Occupation\": \"\",\n",
      "  \"VehicleOwnershipCount\": \"\",\n",
      "  \"VehicleOwnershipPreferences\": \"\",\n",
      "  \"VehicleOwnershipDuration\": \"\",\n",
      "  \"PriceSensitivity\": \"\",\n",
      "  \"SpendingMotivators\": \"\",\n",
      "  \"Values\": \"\",\n",
      "  \"BrandLoyaltyLevel\": \"\",\n",
      "  \"InterestInNewBrands\": \"\",\n",
      "  \"PersonalInterests\": \"fast cars\",\n",
      "  \"ValuesTradition\": \"\",\n",
      "  \"EngagementInitialStages\": \"\",\n",
      "  \"TransactionPreference\": \"\",\n",
      "  \"InformationSeeking\": \"\",\n",
      "  \"ServiceAppointmentPreferences\": \"\",\n",
      "  \"VehicleServicePickUpService\": \"\",\n",
      "  \"LoanerVehicleRequirement\": \"\",\n",
      "  \"TargetDemographic\": \"\",\n",
      "  \"LuxuryExperienceWillingness\": \"\",\n",
      "  \"DigitalEngagement\": \"\",\n",
      "  \"CommunicationPreferences\": \"\",\n",
      "  \"PurchaseDecisionInfluencers\": \"\",\n",
      "  \"BrandPerception\": \"\",\n",
      "  \"EnvironmentalConsciousness\": false,\n",
      "  \"LoyaltyProgramAffiliation\": \"\",\n",
      "  \"FeedbackLikelihood\": \"\",\n",
      "  \"SocialMediaActivity\": \"\",\n",
      "  \"LeisureActivities\": \"\",\n",
      "  \"ShoppingPreferences\": \"\",\n",
      "  \"TechnologyAdoptionRate\": \"\",\n",
      "  \"HealthAndWellnessConcerns\": \"\",\n",
      "  \"EducationLevel\": \"\",\n",
      "  \"FamilyStatus\": \"\",\n",
      "  \"CulturalAffinities\": \"\",\n",
      "  \"AccessibilityRequirements\": \"\",\n",
      "  \"PreferredPaymentMethods\": \"\",\n",
      "  \"TravelFrequency\": \"\",\n",
      "  \"MediaConsumptionHabits\": \"\",\n",
      "  \"RiskTolerance\": \"\",\n",
      "  \"CommunityInvolvement\": \"\",\n",
      "  \"PoliticalViews\": \"Biden is a good president\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Customer(BaseModel):\n",
    "    \"\"\"Data model for a customer behaviour.\"\"\"\n",
    "    Name: str = Field(..., description=\"Name of the customer\")\n",
    "    Type: str = Field(..., description=\"Type of the customer profile\")\n",
    "    Country: str = Field(..., description=\"Country\")\n",
    "    Age: str = Field(..., description=\"Age of the customers\")\n",
    "    AgeGroupWithSignificance: str = Field(..., description=\"Age group with significant presence\")\n",
    "    Gender: str = Field(..., description=\"Gender of the customer\")\n",
    "    IncomeLevel: str = Field(..., description=\"Income level of the customer\")\n",
    "    Residence: str = Field(..., description=\"Customer residences\")\n",
    "    Occupation: str = Field(..., description=\"Common occupations of the customer\")\n",
    "    VehicleOwnershipCount: str = Field(..., description=\"Number of vehicles owned by the customer\")\n",
    "    VehicleOwnershipPreferences: str = Field(..., description=\"Vehicle preferences of the customer\")\n",
    "    VehicleOwnershipDuration: str = Field(..., description=\"Ownership duration of the vehicles\")\n",
    "    PriceSensitivity: str = Field(..., description=\"Price sensitivity of the customers\")\n",
    "    SpendingMotivators: str = Field(..., description=\"Factors motivating customer spending\")\n",
    "    Values: str = Field(..., description=\"Values important to the customers\")\n",
    "    BrandLoyaltyLevel: str = Field(..., description=\"Level of brand loyalty among the customer\")\n",
    "    InterestInNewBrands: str = Field(..., description=\"Customer interest in new brands\")\n",
    "    PersonalInterests: str = Field(..., description=\"Personal interests of the customers\")\n",
    "    ValuesTradition: str = Field(..., description=\"Whether the customers value tradition\")\n",
    "    EngagementInitialStages: str = Field(..., description=\"Initial engagement stages preferred by the customers\")\n",
    "    TransactionPreference: str = Field(..., description=\"Transaction preferences of the customers\")\n",
    "    InformationSeeking: str = Field(..., description=\"Information seeking behavior of the customers\")\n",
    "    ServiceAppointmentPreferences: str = Field(..., description=\"Service appointment preferences\")\n",
    "    VehicleServicePickUpService: str = Field(..., description=\"Preference for vehicle pick-up service\")\n",
    "    LoanerVehicleRequirement: str = Field(..., description=\"Requirement for a loaner vehicle during service\")\n",
    "    TargetDemographic: str = Field(..., description=\"Target demographic for marketing\")\n",
    "    LuxuryExperienceWillingness: str = Field(..., description=\"Willingness for a luxury experience\")\n",
    "    DigitalEngagement: str = Field(..., description=\"Preferred digital platforms and engagement level\")\n",
    "    CommunicationPreferences: str = Field(..., description=\"Preferred methods of communication\")\n",
    "    PurchaseDecisionInfluencers: str = Field(..., description=\"Key influencers of purchase decisions\")\n",
    "    BrandPerception: str = Field(..., description=\"Perception of different brands\")\n",
    "    EnvironmentalConsciousness: str = Field(..., description=\"Awareness and concern for environmental issues\")\n",
    "    LoyaltyProgramAffiliation: str = Field(..., description=\"Participation in loyalty programs\")\n",
    "    FeedbackLikelihood: str = Field(..., description=\"Likelihood to provide feedback or reviews\")\n",
    "    SocialMediaActivity: str = Field(..., description=\"Level of activity on social media platforms\")\n",
    "    LeisureActivities: str = Field(..., description=\"Common leisure activities\")\n",
    "    ShoppingPreferences: str = Field(..., description=\"Preferred shopping channels and styles\")\n",
    "    TechnologyAdoptionRate: str = Field(..., description=\"Rate at which new technology is adopted\")\n",
    "    HealthAndWellnessConcerns: str = Field(..., description=\"Health and wellness concerns and priorities\")\n",
    "    EducationLevel: str = Field(..., description=\"Highest level of education attained\")\n",
    "    FamilyStatus: str = Field(..., description=\"Family composition and marital status\")\n",
    "    CulturalAffinities: str = Field(..., description=\"Cultural groups or activities with which the customer identifies\")\n",
    "    AccessibilityRequirements: str = Field(..., description=\"Any special accessibility requirements\")\n",
    "    PreferredPaymentMethods: str = Field(..., description=\"Favored methods for transactions\")\n",
    "    TravelFrequency: str = Field(..., description=\"Frequency of travel for leisure or business\")\n",
    "    MediaConsumptionHabits: str = Field(..., description=\"Preferred types of media and consumption habits\")\n",
    "    RiskTolerance: str = Field(..., description=\"Willingness to engage in risky activities or investments\")\n",
    "    CommunityInvolvement: str = Field(..., description=\"Level of involvement in local or online communities\")\n",
    "    PoliticalViews: str = Field(..., description=\"Political orientation or views\")\n",
    "    \n",
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(\n",
    "            role=\"system\",\n",
    "            content=(\n",
    "                \"You are an expert assistant for summarizing and extracting personality of a user from a text. If you don't find information, leave is as an empty string.\"\n",
    "            ),\n",
    "        ),\n",
    "        ChatMessage(\n",
    "            role=\"user\",\n",
    "            content=(\n",
    "                \"Here is the text: \\n\"\n",
    "                \"------\\n\"\n",
    "                \"{text}\\n\"\n",
    "                \"------\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=Customer,\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "text = \"Hi, my name is Sarah and love fast cars. I think Biden is a good president\"\n",
    "output = program(text=text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Sarah',\n",
       " 'PersonalInterests': 'fast cars',\n",
       " 'PoliticalViews': 'Biden is a good president'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty_attributes = {k: v for k, v in output.dict().items() if v}\n",
    "non_empty_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20', '75', '70', '65']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "#Map the available persona with the possible classes from people.json\n",
    "def choose_class(persona):\n",
    "    with open('people.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "          # Prepare the prompt for the LLM\n",
    "    scores = [] \n",
    "    for i in data:\n",
    "        prompt = (\n",
    "            f\"Given the following persona attributes:\\n{persona}\\n\\n\"\n",
    "            f\"And the type defined in:\\n{i}\\n\"\n",
    "            \"Provide a score, how similar they are from 1 to 100. Only give a number.\"\n",
    "        )\n",
    "        response = OpenAI().complete(prompt).text\n",
    "\n",
    "        \n",
    "        scores.append(response)\n",
    "        \n",
    "    print(scores)\n",
    "    max_score_index = scores.index(max(scores, key=int))\n",
    "    \n",
    "    return max_score_index\n",
    "\n",
    "choose_class(non_empty_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-0613\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# main = index.as_query_engine(similarity_top_k=3)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# query_engine_tools = [\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m agents_dict, extra_info_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m build_agents(documents)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#agent = ReActAgent.from_tools(query_engine_tools, llm=llm, verbose=True)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(agent.chat('What do you know?'))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 169\u001b[0m, in \u001b[0;36mbuild_agents\u001b[0;34m(docs)\u001b[0m\n\u001b[1;32m    164\u001b[0m extra_info_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# # this is for the baseline\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# all_nodes = []\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    170\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m node_parser\u001b[38;5;241m.\u001b[39mget_nodes_from_documents([doc])\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# all_nodes.extend(nodes)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# ID will be base + parent\u001b[39;00m\n",
      "File \u001b[0;32m~/programming/makethon-nlp/.venv/lib/python3.10/site-packages/tqdm/notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/programming/makethon-nlp/.venv/lib/python3.10/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = read_data('data/')\n",
    "#llama.save_emb(documents, 'storage/')\n",
    "#index = build_index(documents)\n",
    "#llm = OpenAILike(model=\"NousResearch/Hermes-2-Pro-Mistral-7B\",api_base=\"http://localhost:8000/v1\", api_key=\"fake\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "# main = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=main,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"main\",\n",
    "            description=\"Provides information the data \"\n",
    "            \"Use a detailed plain text question as input to the tool.\",\n",
    "        ),\n",
    "    )\n",
    "]\n",
    "agents_dict, extra_info_dict = await build_agents(documents)\n",
    "#agent = ReActAgent.from_tools(query_engine_tools, llm=llm, verbose=True)\n",
    "\n",
    "#print(agent.chat('What do you know?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
