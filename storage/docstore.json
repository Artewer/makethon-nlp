{"docstore/data": {"2c78e2df-0fc2-4f9d-93ca-08dc4ce41c8e": {"__data__": {"id_": "2c78e2df-0fc2-4f9d-93ca-08dc4ce41c8e", "embedding": null, "metadata": {"page_label": "a", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "SCHOOL OF COMPUTATION,\nINFORMATION AND TECHNOLOGY \u2014\nINFORMATICS\nTECHNICAL UNIVERSITY OF MUNICH\nBachelor\u2019s Thesis in Information Systems\nLearning Methods for Iterative\nCombinatorial Auctions\nArtem Melnychuk", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "314d4bf7-8bc2-489e-bcd8-f0d51d466f5a": {"__data__": {"id_": "314d4bf7-8bc2-489e-bcd8-f0d51d466f5a", "embedding": null, "metadata": {"page_label": "i", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "SCHOOL OF COMPUTATION,\nINFORMATION AND TECHNOLOGY \u2014\nINFORMATICS\nTECHNICAL UNIVERSITY OF MUNICH\nBachelor\u2019s Thesis in Information Systems\nLearning Methods for Iterative\nCombinatorial Auctions\nLernmethoden f\u00fcr iterative kombinatorische\nAuktionen\nAuthor: Artem Melnychuk\nSupervisor: Prof. Dr. Martin Bichler\nAdvisor: Eleni Batziou M.Sc.\nSubmission Date: 15.09.2023", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "d50f3577-c540-4add-a2fa-59f70aae1a03": {"__data__": {"id_": "d50f3577-c540-4add-a2fa-59f70aae1a03", "embedding": null, "metadata": {"page_label": "ii", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "I confirm that this bachelor\u2019s thesis is my own work and I have documented all sources\nand material used.\nMunich, 15.09.2023 Artem Melnychuk", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "039374eb-cff8-4c17-a8ae-48feede2253e": {"__data__": {"id_": "039374eb-cff8-4c17-a8ae-48feede2253e", "embedding": null, "metadata": {"page_label": "iii", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Acknowledgments\nFirst I would like to thank my advisor, Eleni Batziou, for her guidance and support\nthroughout the process of writing this thesis. When I pitched an idea, she distilled its\nessence. When my experimental drafts were far from perfect, she patiently reviewed\nthem and always gave me a hint of how to improve them. I am very grateful for her\nunderstanding, as well as her willingness to share her knowledge and invest her time\nin my work.\nI have been fortunate to learn from Hayim Malkhasy, who has always provided\nunique perspectives and insightful comments. My thinking and work ethic was shaped\nby our thoughtful discussions. I am also grateful for his review and encouragement\nthroughout the process of writing this thesis.\nIt was a great pleasure to discuss research ideas with Sarthak Parikh and see his\npassion for science. This also includes Kiril Ratarov and his uncanny ability to recognize\npitfalls in various approaches to the problem.\nA big thank to my brother who helped me with analyzing my experiments as well as\nalways having my back. And to my parents, who sacrificed the comfort of staying in\nUkraine to move to Germany allowing me to grasp new opportunities and chase my\nambitions.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "117fa057-7f88-410f-992c-18219faba31f": {"__data__": {"id_": "117fa057-7f88-410f-992c-18219faba31f", "embedding": null, "metadata": {"page_label": "iv", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Abstract\nThe efficiency of combinatorial auctions is of high importance to multiple industries\nand organizations. Recent methods are incorporating machine learning and linear\noptimization into the process to improve the welfare of each participant and optimize\nallocations. Due to the nature of combinatorial auctions, bidders can only report a\nlimited amount of preferences in the exponential space of possibilities. We explore\nthe usage of active learning methods to improve the informativeness of each bundle\nto increase the efficiency of the allocation. We compare and test the efficiency and\nruntime of the auctions using Uniform Sampling, Greedy Farthest-First Traversal,\nGreedy Farthest-First Traversal Reverse, Greedy Active Learning on Input Values and\nGreedy Active Learning on Output Values. Our approach improves the efficiency of\nthe iterative combinatorial auctions.\niv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "7a3d2470-9999-47b2-98ab-0918363e87db": {"__data__": {"id_": "7a3d2470-9999-47b2-98ab-0918363e87db", "embedding": null, "metadata": {"page_label": "v", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Contents\nAcknowledgments iii\nAbstract iv\n1 Introduction 1\n1.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2 Preliminaries 5\n2.1 Combinatorial Auctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.1 Vickrey-Clarke-Groves Auction . . . . . . . . . . . . . . . . . . . . 6\n2.2 Machine Learning-based Combinatorial Auction . . . . . . . . . . . . . . 7\n2.2.1 Machine Learning-powered Query Module . . . . . . . . . . . . . 7\n2.2.2 Design Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.3 MLCA Mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.4 Deep Learning-powered Iterative Combinatorial Auctions . . . . 9\n3 Active Learning 11\n3.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.2 GFFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.3 GFFT: Reverse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.4 Greedy Active Learning on Input Values . . . . . . . . . . . . . . . . . . 15\n3.5 Greedy Active Learning on Output Values . . . . . . . . . . . . . . . . . 17\n3.5.1 Greedy Active Learning on Output Values: Linear Model . . . . 17\n3.5.2 Greedy Active Learning on Output Values: Neural Network . . 19\n4 Results 22\n4.1 Experiment setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.2 Spectrum Auction Test Suite . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.3 Hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nv", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "6b87f6e1-dc86-416f-bfaf-ac1eaacd8679": {"__data__": {"id_": "6b87f6e1-dc86-416f-bfaf-ac1eaacd8679", "embedding": null, "metadata": {"page_label": "vi", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Contents\n4.4 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.4.1 GSVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.4.2 LSVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.4.3 MRVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5 Conclusion 34\nAbbreviations 35\nList of Algorithms 37\nList of Figures 38\nList of Tables 39\nBibliography 40\nvi", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "608b7309-18ab-4a90-bdb7-a14abb92881b": {"__data__": {"id_": "608b7309-18ab-4a90-bdb7-a14abb92881b", "embedding": null, "metadata": {"page_label": "1", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "1 Introduction\n1.1 Overview\nCombinatorial auctions provide a sophisticated mechanism for allocating diverse sets of\nitems to various bidders to attain an optimal solution. The optimal solution is defined\nas the allocation that maximizes the total utility of all bidders. This process faces\nsignificant challenges: limitation on the bundle submission, exponential growth of\nfeasible bundles, computational restrictions and bidder reporting.\nContemporary models of combinatorial auctions impose constraints on bidders by\nrestricting the number of bundles they can submit. Such restrictions can hinder the\nattainment of an efficient allocation.\nThe feasible set of bundles expands exponentially with the addition of each item. This\nexponential growth complicates the computational process, imposing a substantial\nbarrier to the scalable allocation of goods, particularly in larger domains.\nThe inherent complexity of the exponential growth in the amount of bundles leads\nto computational constraints. Given a limited amount of reported bundles, these\nlimitations restrict the auctioneer\u2019s ability to discern the true valuations of bidders\u2019\npreferences. Thus, it is only possible to approximate each bidder\u2019s value function.\nBidders often find themselves restricted in their capacity to report the most infor-\nmative bundles (Scheffel et al. 2012; Bichler, Shabalin, and Wolf 2013). This constraint\ndirectly impacts the maximization of allocation efficiency.\nThe underlying design of the auctions may sometimes provide incentives to bidders\nto withhold their true valuations rather than fully reveal them. Furthermore, in\nthe context of real-world applications of combinatorial auctions, bidders may lack\ncomprehensive insight into the underlying mechanisms governing the auction process.\nThe reporting of bundles may be influenced more by personal preferences than by a\nstrategic understanding of optimal allocation principles.\nProgress: These challenges were thoroughly addressed by researchers, as evidenced\nby the work of Brero, Lubin, and Seuken (2021), serving as a platform to explore and\nevaluate diverse machine learning techniques in predicting user valuations. Those\ntechniques tacked the problems of computational constraints and bidder reporting by\nusing machine learning models to approximate the value functions of bidders.\nA promising approach within this framework involved the integration of neural\n1", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "01bac0bd-9224-4b2c-b984-15118458a84a": {"__data__": {"id_": "01bac0bd-9224-4b2c-b984-15118458a84a", "embedding": null, "metadata": {"page_label": "2", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "1 Introduction\nnetworks with Mixed-Integer Programming ( MIP) (Weissteiner and Seuken 2020).\nGiven the success of this approach, further methods have been developed to improve\nthe efficiency of combinatorial auctions: Bayesian Optimization (Weissteiner et al. 2023)\nand Fourier based approach (Weissteiner et al. 2022). The results of those works have\nshowed that the efficiency of combinatorial auctions can be improved by using machine\nlearning techniques.\nRemaining Challenges: Despite the progress achieved, significant challenges remain,\nespecially in large domain auctions characterized by many bidders and items where\neach bidder\u2019s value function becomes more complex. This abundance of elements\nresults in a multitude of potential combinations, complicating the analysis of such\nauctions. An illustration of these complexities can be found in the Canadian spectrum\nauctions (Taylor 2013), where at some point in time there were 298possible bundles,\nwhich approximates 3.16\u00b71029possibilities. Meanwhile bidders could only report their\ntrue valuations for 500 bundles.\nOutline of contributions: In this thesis, the focus is placed on the application and\ninnovation of active learning techniques to enhance the efficiency of combinatorial auc-\ntions. This paper deals with the initial round of the auction process, where bidders must\nreport their valuations of a limited number of bundles. Specifically, the work includes\nthe implementation of two distinct methodologies: Greedy Active Learning on Input\nValues ( GALI ) and Greedy Active Learning on Output Values ( GALO ) (Estermann\net al. 2023). Moreover, the thesis introduces another learning strategy designed for\ncombinatorial auctions - Greedy Farthest-First Traversal ( GFFT ) and a similar method\nGreedy Farthest-First Traversal (reverse) ( GFFT(reverse) ). The results of these methods\nare compared to the baseline of Uniform Sampling ( UF) in Deep Learning-powered\nIterative Combinatorial Auctions (Weissteiner and Seuken 2020).\nMotivations: The initial round of the auction dictates the efficiency and progress\nof the subsequent iterations of auctions. Iterative combinatorial auctions are used\nextensively in practice. From 2008 to 2014, in ten countries which were using spectral\nauctions, there were around fifteen instances of auctions creating $ 20 Billion in total\nrevenue (Ausubel and Baranov 2017). A moderate 1-2% increase in efficiency will\ntranslate to millions in revenue. Therefore, it\u2019s evident that improving auction mecha-\nnisms can positively impact the economy making it a worthwhile endeavor. Having an\ninterest in such pursuit, this thesis not only contribute to the market efficiency but also\nfosters economic growth, thereby serving as an accelerator for societal advancement.\nChallenges of this approach: The approach of adding active learning techniques\nto iterative combinatorial auctions influences the subsequent iterations of the auction.\nThe overall runtime can be increased significantly. The design of the algorithms is\ninfluenced by the computational complexity of the auction. The researcher has to decide\nbetween the tradeoff of better efficiency or shorter runtime. In this case study, the\n2", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "e9337a48-bf37-4ee8-bb6e-0d7cc843dc60": {"__data__": {"id_": "e9337a48-bf37-4ee8-bb6e-0d7cc843dc60", "embedding": null, "metadata": {"page_label": "3", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "1 Introduction\nprinciples of the GFFT algorithms are leveraged to illustrate these dynamics, offering\ninsights into fine-tuning active learning for speed and efficiency.\n1.2 Related work\nCombinatorial auctions have been the subject of extensive research over the past decades,\nwith applications spanning various domains. Hershberger and Suri (2001) applied these\nauctions to network routing, while Caplice (1996) investigated their use in optimizing\ndelivery routes. Additionally, Rassenti, Smith, and Bulfin (1982) studied combinatorial\nauctions in the context of airport slot allocations, and Brewer (1999) explored their\napplication in railroad segments.\nAmong the most influential work for the preferences elicitation in combinatorial\nauctions are papers by Blum et al. (2003) and Lahaie and Parkes (2004). These introduce\nnew elicitation learning algorithms and were further developed when the researchers\nintroduced ML-based approaches to determine prices that guide bidders toward effi-\ncient allocations (Lahaie and Lubin 2019). Bayesian auctions were designed and built\nupon previous works to approximate competitive equilibrium prices in the works of\nBrero and Lahaie (2018) and Brero, Lahaie, and Seuken (2019).\nAnother line of research originated from the works of Conitzer and Sandholm (2002,\n2004), focusing on formulating a space of possible solutions and then using a search\nproblem to map bidders\u2019 preferences to bid profiles. More recently, Duetting et al. (2019)\nemployed deep learning to enhance the design of revenue-maximizing auctions.\nThe work of Brero, Lubin, and Seuken (2021) and Weissteiner and Seuken (2020)\nare the most recent examples of using Support Vector Regression ( SVR ) and Deep\nNeural Network ( DNN ) respectively to approximate the value functions of bidders for\ngenerating new profiles of bundles.\nAs for active learning, while there is extensive work being done for classification\nproblems, there is still a lack of research in the field of regression. A substantial amount\nof labeled samples are needed to train an accurate regression model. Instead of random\nselection, Wu, Lin, and Huang (2018) proposed to use geometric feature space of\ninput and output of the model to increase diversity of the samples. By calculating\nexpected model change for regression problems (Park and Kim 2020), it is possible to\nmake choosing labels more robust by avoiding outliers, which do not contribute to\nthe improvement of the model. Wu (2018) proposed to extend criteria for pool-based\nactive learning, incorporating such things as informativeness, representativeness and\ndiversity. These methods can also be applied to combinatorial auctions, as they are not\nrestricted to a specific domain.\n3", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "304663c4-882b-45f2-b1f6-d2798ee5a563": {"__data__": {"id_": "304663c4-882b-45f2-b1f6-d2798ee5a563", "embedding": null, "metadata": {"page_label": "4", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "1 Introduction\n1.3 Contributions\nThe goal of this paper is to increase the efficiency of auctions by querying the bidder\nwith most important initial bundles. By iteratively discovering the most informative\nbundles, true preferences of a bidder are successfully learned, allowing for efficient\nbundle allocation and ensuring high efficiency with low auction runtime.\nFirstly, we extend the work of Brero, Lubin, and Seuken (2021) by incorporating\nactive learning methods into the framework. This would allow future research in active\nlearning in combinatorial auctions to be more flexible, as it is not restricted to only\nusing UF for the initial bundles.\nSecondly, this paper contributes by implementing GALI and GALO algorithms\n(Estermann et al. 2023). These algorithms are being tested on the Generalized Value\nModel ( GSVM ), Linearly Correlated Value Model ( LSVM ) and Multi-Region Value\nModel ( MRVM ) domains. The results are compared to the baseline of UFin Deep\nLearning-powered Iterative Combinatorial Auctions (Weissteiner and Seuken 2020).\nThey show a considerable improvement in efficiency of the auctions.\nNext, we propose GFFT and GFFT(reverse) algorithms, which are particularly useful\nfor smaller auction domains. The results of GFFT and GFFT(reverse) are compared\nto the results of GALI and GALO algorithms. We show how GFFT and GFFT(reverse)\nperform even better in efficiency than other algorithms in smaller scale domains. This\nthesis contributes by showing that active learning methods can be used to improve the\nefficiency of combinatorial auctions.\n1.4 Outline\nThis thesis is organized in the following structure. Chapter 1 provides an overview\nof the thesis, its contributions and the outline of the work. Chapter 2 introduces the\npreliminaries of understanding iterative combinatorial auctions, the work involved\nwith optimizing them. It also introduces the important notation and definitions used\nthroughout the thesis. Chapter 3 introduces active learning methods, describing the\nalgorithms and providing their implementation. Chapter 4 presents the results of the\nexperiments and the performances of the algorithms.\nGiven the findings, Chapter 5 concludes the thesis and provides an outlook on future\nresearch directions.\n4", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "63165103-14a0-45e8-aea7-675e6a1b726f": {"__data__": {"id_": "63165103-14a0-45e8-aea7-675e6a1b726f", "embedding": null, "metadata": {"page_label": "5", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\n2.1 Combinatorial Auctions\nAuction is a process of buying or selling goods or services by bidding. Generally, the\nitem is sold to the highest bidder and is bought from the lowest bidder. Combinatorial\nauctions are a type of auction that allows bidders to submit bids on a combination of\nitems. Those combinations are called bundles and having a different combination of\nitems produces a complementary effect for bidders. Meaning that the combinations\nof some items in the bundle are more or less valued according to different types of\nbidders. Notation is defined to support the claims:\nLetN={1, 2, . . .,n}denote the set of bidders participating in an auction, and let\nM={1, 2, . . .,m}represent the set of indivisible items that are being auctioned off.\nWithin this context, the set Nis referred to as the main economy , whereas any subset\nN\\ {i}is termed a marginal economy .\nAbundle of items is represented as a vector Xof{0, 1}m, where each element in the\nvector indicates the presence or absence of an item in the bundle.\nThe preferences of each bidder iare encapsulated by a valuation function ui:\nX\u2192R\u22650. In this function, ui(x)quantifies the true value that bidder iassigns to\nobtaining bundle x. For the entire profile of bidders, the valuation vector is denoted as\nu={u1,u2, . . . , un}.\nImportant parameters for this work are Qmax,Pmaxand Qinit.Qmaxis the maximum\namount of queries per bidder, Pmax, is the maximum amount of push bids per bidder\nand Qinit, is the amount of initial queries. Those parameters are influencing the amount\nof rounds in Machine Learning Combinatorial Auction (MLCA) algorithm\nAnallocation for all bidders is represented by the vector a={a1,a2,. . .,an}, where ai\ndenotes the allocation of items to bidder i. An allocation is termed feasible if each item\ninMis allocated to at most one bidder.\nPayments made by the bidders are captured by the payment vector p={p1,p2,. . .,pn},\nwhere pirepresents the payment charged to bidder i. The utility function for each\nbidder iis defined as a quasi-linear function ui(a,p) =ui(ai)\u2212pi.\nThe cumulative true values of bidders for an allocation constitute its social welfare,\nwhich is defined as V(a) =\u2211i\u2208Nui(a). The efficiency of any given allocation ais\ndenoted by Eff(a), and is defined as the ratio of the total valuation for allocation ato\n5", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "c5393fff-1ed0-4c4b-a879-b6611cd9c8ee": {"__data__": {"id_": "c5393fff-1ed0-4c4b-a879-b6611cd9c8ee", "embedding": null, "metadata": {"page_label": "6", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\nthe total valuation for the optimal allocation a\u2217, i.e.,\nEff(a) =V(a)\nV(a\u2217)(2.1)\n2.1.1 Vickrey-Clarke-Groves Auction\nThis section introduces the concept of Vickrey-Clarke-Groves auction ( VCG ) (Vickrey\n1961; Clarke 1971; Groves 1973), a class of auctions known for their strategy-proof\nproperties:\nThe allocation rule is given by aVCG\u2208arg max a\u2208F\u2211i\u2208Nui(ai), whereas the payment\nrule is defined as:\npi\nVCG=\u2211\nj\u2208N\\{i}uj(a\u2212i\nj)\u2212\u2211\nj\u2208N\\{i}uj(aVCG\nj) (2.2)\n,\nwhere an optimal item allocation a\u2212iis defined as:\na\u2212i\u2208arg max\na\u2208F\u2211\nj\u2208N\\{i}uj(aj) (2.3)\nVCG is characterized by incentive compatibility, which encourages participants to\nreveal their true valuations. Formally, the mechanism is strategy-proof , implying that\neach bidder maximizes their utility by truthfully disclosing their valuation, irrespective\nof the strategies adopted by others.\nFor the VCG to be efficient, several conditions must be met:\n1.Rationality : It is assumed that all bidders are rational agents who aim to maximize\ntheir individual utilities.\n2.Absence of Bid Collusion : The mechanism assumes that no collusive behavior exists\namong the bidders.\n3.Unique Identity : A single bidder is not permitted to submit bids under multiple\nidentities.\nIf the conditions are satisfied, then truthful reporting of valuations creates a weakly\ndominant strategy, effectively making any alternative strategy profiles suboptimal.\nHowever, the VCG is not viable for combinatorial auctions as it requires a full\nvaluation profile of each bidder as it is written in Equation 2.2. Mishra and Parkes (2007)\nand Vries, Schummer, and Vohra (2007) have introduced iterative VCG mechanism.\nThese iterative mechanisms are designed to engage with bidders by systematically\neliciting information across multiple rounds of interaction.\n6", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "9254db6a-6a6b-4b61-8125-626fabcf1596": {"__data__": {"id_": "9254db6a-6a6b-4b61-8125-626fabcf1596", "embedding": null, "metadata": {"page_label": "7", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\n2.2 Machine Learning-based Combinatorial Auction\nThe MLCA is an auction mechanism that utilizes iterative rounds and incorporates\nmachine learning algorithms to approximate the valuation functions of participating\nbidders. During each round, bidders receive new queries concerning both their marginal\nand main economic preferences.\nFor each bidder i\u2208Nthere is a unique algorithm Ji, which processes the reported\nbundle-value pairs Ri. In this specific implementation (Weissteiner and Seuken 2020),\nJicorresponds to a Deep Neural Network (DNN). Each DNN, trained on Ri, learns an\nestimated valuation function vithat can predict the value of any potential bundle for\nthe corresponding bidder i.\nThe primary objectives of MLCA diverge from those of traditional VCG auctions\nin several key aspects. Firstly, MLCA aims to impose constraints on the volume\nof submitted bids, as opposed to the unconstrained bidding typically observed in\nVCG auctions. This constraint serves to accommodate realistic combinatorial auction\nscenarios, where bidders are often limited in their capacity to submit bids. In this\nimplementation, for each bidder, the number of bids is limited to Qmax-Pmax.\nSecondly, MLCA is designed to establish a robust framework explicitly tailored for\niterative combinatorial auctions. Such a framework provides a foundational bedrock,\nupon which comparable baselines can be constructed for future research endeavors in\nthis domain.\n2.2.1 Machine Learning-powered Query Module\nA dedicated query module powered by machine learning is employed to calculate\nthe Winner Determination Problem ( WDP ). The query module accepts a parameter\nset, comprising a profile of machine learning algorithms for each bidder, an array\nof economies, and a profile consisting of bundles alongside their reported values.\nAfterwards, the module trains separate algorithms on the bundle-value pairs, finding\nvaluation functions uiMathematically, the social welfare is denoted as V(a) =\u2211iui,\nwhere uirepresents the individual welfare attributable to a given bidder i. It is used as\na objective function to be maximized by the ML-based WDP . All valuation functions vi\nare fed into ML-based WDP to calculate the allocation aMLCA , where queries are being\ngenerated for a specific bidder to achieve this allocation. In the Algorithm 1 the query\nmodule is represented as NextQueries function.\n2.2.2 Design Elements\nThere exist four design elements that dictate the functionality of the MLCA:\n7", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "2a88c970-74ef-444a-84c3-5f06b9c8288d": {"__data__": {"id_": "2a88c970-74ef-444a-84c3-5f06b9c8288d", "embedding": null, "metadata": {"page_label": "8", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\n1.Allocation is based on the reported bundle-value pairs, not on the learned valua-\ntion functions.\n2. VCG payments are based on bundle-value pairs.\n3. MLCA queries marginal economies of each individual bidder.\n4. Bidders can submit or \u2019push\u2019 their bids.\nChanging the underlying VCG mechanism to an iterative form no longer allows for\nthe assumption that the mechanism is immune to manipulations. In their study, Brero,\nLubin, and Seuken (2021) argues that these design choices promote good incentives\nand make any possible manipulation strategies impossible to execute successfully. No\napproximation is involved in calculating bundle-value pairs, meaning the allocation\nis based on the truthful and constant reporting of bidders. Thus, the allocations are\nalways reproducible and do not allow randomness. When a bidder\u2019s marginal economy\nis independent of his reports, the only way to increase his utility is by enhancing the\nsocial welfare of the main economy through truthful value reporting.\nMLCA framework offers a dynamic and adaptable system designed to make auction\nprocesses more flexible. Bidders can push bids that they deem informative to the\nauction mechanism. There is a specified limit on the number of bids each bidder\ncan submit, preventing potential abuse or congestion. The auctioneer retains control\nover the number of rounds during an auction. This control is facilitated through a\nvariable, denoted as Qround , which controls the number of queries asked each round.\nThe default payment rule is VCG . This VCG module can be easily exchanged for\nalternative payment rules, thereby accommodating diverse auction requirements and\nobjectives.\n2.2.3 MLCA Mechanism\nCombining these details results in a fully-fledged model, described step by step in\nAlgorithm 1.\n\u2022Initialization phase (Line 1-8), bidders push bids and are asked to report their\nvalues for randomly chosen bundles.\n\u2022Iteration phase (Line 9 - 25), for every round t choose a sample of bidders and\ngenerate new queries for them using NextQueries. Calculate query profile for\nmain economy. Get reported values for bids from bidders.\n\u2022 Final allocation phase (Line 26 - 30), compute final allocation and payments.\n8", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "31dc84f6-3ea1-4454-ac69-a072260125c7": {"__data__": {"id_": "31dc84f6-3ea1-4454-ac69-a072260125c7", "embedding": null, "metadata": {"page_label": "9", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\nThe initialization phase is tackled in this work. In line 4-5, there is a process of\ngenerating random initial bids for Qinit. As this process influences all following\niterations, it is essential to optimize it. Brero, Lubin, and Seuken (2021) argue that\nrandomizing initial samples is one of the design choices of the MLCA to promote\nthe strategy-proof properties as the bidders cannot predict which bundles did other\nparticipants get. To support this phenomenon, uniform sampling is still employed in\nsome of the algorithms.\n2.2.4 Deep Learning-powered Iterative Combinatorial Auctions\nThe initial formulation of the MLCA mechanism employed SVR as the underlying\nmachine learning model. In contrast, the current method leverages DNN (Weissteiner\nand Seuken 2020) with RELUs turned into MIP for resolving the WDP to generate the\nsubsequent query profile. The integration of a machine learning algorithm into the\nMLCA framework primarily influences two facets: the estimation step and the optimiza-\ntion step . During the estimation phase, the chosen machine learning model predicts the\nbidders\u2019 valuations for the next auction round. Afterwards, in the optimization phase,\nthe model is tasked with solving the WDP . Weissteiner and Seuken (2020) argued\nthat SVR have limited expressiveness and cannot be effectively used in large auction\ndomains.\n9", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "fb50424d-e2dc-4a80-9fe0-f1962d0ea8cf": {"__data__": {"id_": "fb50424d-e2dc-4a80-9fe0-f1962d0ea8cf", "embedding": null, "metadata": {"page_label": "10", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "2 Preliminaries\nData: Profile of ML algorithms M, maximum amount of queries per bidder Qmax,\namount of initial queries Qinit\u2264Qmax, amount of queries per round\nQround , maximum amount of push bids per bidder Pmax\nResult: Final allocation aMLCA and payments pMLCA\n1foreach bidder i \u2208Ndo\n2 receive Pi\u2264Pmaxpush bids;\n3end\n4foreach bidder i \u2208Ndo\n5 ask bidder to report his value for Qinitrandomly chosen bundles;\n6end\n7LetR= (R1, . . . , RN)denote the initial report profile;\n8LetT=j\nQmax\u2212Qinit\nQroundk\nand t=1 denote the number of auction rounds and the\ncurrent round, respectively;\n9while t\u2264Tdo\n10 LetS= (S1, . . . , Sn)denote the profile of queries for this auction round;\n11 foreach bidder i \u2208Ndo\n12 Sample a set of bidders N\u2032\u2286N\\ {i}with|N\u2032|=Qround\u22121;\n13 foreach i\u2208N\u2032do\n14 Generate query profile qi:=NextQueriesJ(N\u2032\\ {i},R\u2032\n\u2212i,S\u2032\n\u2212i)for\nbidder i;\n15 Si=Si\u222a {qi};\n16 end\n17 end\n18 Generate query profile q:=NextQueriesJ(N,R,S);\n19 foreach bidder i \u2208Ndo\n20 Si=Si\u222a {qi};\n21 send new queries Sito bidder iand wait for reports;\n22 receive bundle-value reports R\u2032\niand add them to Ri;\n23 end\n24 t=t+1;\n25end\n26Letvidenote bidder i\u2019s report function capturing bundle-value reports\nRi,\u2200i\u2208N;\n27Compute final allocation aMLCA =arg max a\u2208F\u2211i\u2208Nvi(ai);\n28foreach bidder i \u2208Ndo\n29 pMLCA\ni=\u2211j\u2208N\\{i}vj(a\u2212i\nj)\u2212\u2211j\u2208Nvj(aMLCA\nj), where\na\u2212i\u2208arg max \u2211j\u2208N\\{i}vj(aj);\n30end\nAlgorithm 1: Machine Learning-powered Combinatorial Auction (MLCA)\n10", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "f90a6c30-5bee-47fb-8d20-d3464b744e07": {"__data__": {"id_": "f90a6c30-5bee-47fb-8d20-d3464b744e07", "embedding": null, "metadata": {"page_label": "11", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\n3.1 Overview\nA profound idea behind a concept of active learning is to reduce the amount of data\nneeded to train a model. There are cases in which unlabeled data is abundant but\nrequires labeling. In such scenarios, active learning algorithms can be used to reduce\nthe amount of data to be labeled by selecting the most informative data points. The\nmodel has the ability to query the oracle (usually a human annotator) for labels of data\ninstances that it finds most \"informative\". Here is a breakdown of the major types of\nactive learning:\n\u2022Pool-Based Sampling: the model evaluates each instance and picks the ones where\nit\u2019s most uncertain. The model queries instances for which it is most uncertain,\ntypically those where the predicted probabilities are closest to 0.5 or the entropy\nis highest.\n\u2022Stream-Based Selective Sampling: instances come in a stream, one at a time.\nYour model has to make an immediate decision whether to query a label for\neach instance. There is a threshold for uncertainty, and if the model is uncertain\nbeyond that threshold, it queries the label.\n\u2022Query-By-Committee: multiple models are trained on the same data. They \u2019vote\u2019\non each unlabeled instance. If there\u2019s discord, i.e., high variance in predictions,\nthe instance is queried.\n\u2022Expected Error Reduction: the model computes the expected error reduction for\neach unlabeled instance. It queries the instance that is expected to reduce the\nerror the most.\n\u2022Variance Reduction: the model computes the variance of the model parameters\nfor each unlabeled instance. It queries the instance that is expected to reduce the\nvariance the most.\n\u2022Bayesian Active Learning: the model computes the posterior probability of each\nunlabeled instance. It queries the instance that is expected to maximize the\nposterior probability.\n11", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "ccd5cb81-46a6-4ce3-9a25-ff0ef175e32b": {"__data__": {"id_": "ccd5cb81-46a6-4ce3-9a25-ff0ef175e32b", "embedding": null, "metadata": {"page_label": "12", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\n\u2022Reinforcement Learning based: the model learns a policy to select the most\ninformative instances to query.\nThis paper focuses on the Pool-Based Sampling approach, as it is the most applicable\nto the MLCA domain.\nWu (2018) proposes three criteria to be considered in pool-based sampling:\n\u2022Informativeness: samples, which are selected, must contain rich information. This\nis measured in entropy, distance to the decision binary, expected model change\netc.\n\u2022 Representativeness: number of samples, which represent the whole variance.\n\u2022 Diversity: how samples are scattered around the full space.\nThe main idea behind pool-based approach is to select the most informative bundles\nfrom the available pool of bundles. The metrics in this paper are defined differently per\nactive learning algorithms. However, the main idea is to query a bundle with the largest\n\"distance\" from the already selected bundles. For GFFT ,GFFT(reverse) and GALI the\ndistance is calculated between the input values (bundles), and for GALO the distances\nis calculated between the output values (values of bundles). Increasing the information\ngain per bundle reduces the number of bundles that need to be sampled. We enhance\ninformativeness by choosing bundles that have the greatest distance from the bundles\nalready selected. In our experiments, representativeness is a constant number, which\nmeans every algorithm has a limited number of samples available. We measure the\ndiversity parameter using the distance between bundles. In other words, the more\ndistant the selected bundles are, the more diverse the sample becomes.\nMain problem in active learning for auctions is that the majority of the research in\nthis area is being done in the context of text classification, image classification, etc.\nThose methods are usually not applicable to combinatorial auctions, because those\nmethods are used for classification problems, while combinatorial auctions require\nactive learning solutions to regression problems. In contrast to the diversity of image\nor text data, combinatorial auctions feature a set of bundles that are monotonous and\npredictable.\nThe core mechanism of the MLCA utilizes a UFtechnique for selecting an initial\nsubset of bundles from a considerably large set. UFis a probabilistic method used\nto extract a representative subset of data elements, denoted as S, from a larger data\npopulation X. The underlying principle behind this sampling technique is that each\nelement x\u2208 X has an equal probability, p(x), of being selected. This probability for\nUF can be mathematically represented as follows:\n12", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "2fbc48b7-8884-4606-847a-1b7772d6cc30": {"__data__": {"id_": "2fbc48b7-8884-4606-847a-1b7772d6cc30", "embedding": null, "metadata": {"page_label": "13", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\np(x) =1\n|X|,\u2200x\u2208 X (3.1)\nThe computational complexity of generating a sample Sis generally O(n), assuming\nrandom access to X.UFis widely applied in various domains for its simplicity and\nefficiency. However, it might not be suitable for populations with high variance, such\nas the MRVM auction domain discussed in this thesis.\nThe cardinality of this subset, denoted as |S|, usually spans between 30 and 100 per\nauction model in the implementation. This range helps to achieve increased efficiency\nwithout significantly impacting runtime, even through this quantity might seem trivial\nwhen compared to the totality of available bundles. As |S|grows, the computational\ncomplexity of preference allocation escalates exponentially. In real-world scenarios,\nhandling such complexity becomes infeasible. Therefore, it is essential to devise\nmethodologies to minimize the number of bundles to be sampled, ensuring optimal\nefficiency without compromising runtime.\n3.2 GFFT\nA Greedy Farthest-First Traversal (GFFT) algorithm is developed as a preliminary\nmethod for computing the distance between specific clusters of bundles and the rest of\nthe bundles in the given set. The intent of this approach is to maximize entropy, aiming\nto explore previously not encountered combinations of items. This algorithm proves\nparticularly useful in performance evaluation within smaller domains.\nThe computational complexity of the algorithm is expressed in O(n2)steps and O(n2)\ndistance computations, making it suitable for smaller auction settings.\nFormal Definition: LetSbe a selected subset of bundles, and X \\ S be the universal\nset containing all available bundles. The subsequent bundle to be incorporated into S,\ndenoted as x\u2217, is determined as:\nx\u2217=arg max\nx\u2208X||x\u2212 S|| \u2200 x\u2208X (3.2)\nThis formulation facilitates the selection of the bundle that maximizes its distance\nfrom the existing set S. This GFFT is employed to benchmark both runtime and effi-\nciency for smaller domains. The distance between XandSis computed by employing\nEuclidean metrics.\nThe details for the algorithm are provided in Algorithm 2.\nAlthough this algorithms\n13", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "3d528bf3-6ca9-44d8-a96a-499f92505218": {"__data__": {"id_": "3d528bf3-6ca9-44d8-a96a-499f92505218", "embedding": null, "metadata": {"page_label": "14", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nAlgorithm 2: GFFT\nData: Amount of bundles n\nResult: Matrix Scontaining selected bundles and their values\nX\u2190generate available bundles\nb0\u2190random element from X\nS\u2190\u2205\nS[0]\u2190b0\nfori from 1to n\u22121do\ndist x\u2190calculate Euclidean distance between X and S\nx\u2217=arg max x\u2208Xdist x\nS[i]\u2190x\u2217\nend\nS\u2190append values for each bundle provided by bidder\nreturn S\n3.3 GFFT: Reverse\nIn contrast to the original greedy algorithm, the present variant employs a similar\nheuristic but introduces an optimization to mitigate the computational burden of\ndistance calculations in exponential time. By leveraging the inherent data characteristics,\nvector bundles can be transformed to reflect the frequency of individual items.\nFormal Definition: LetSdenote a selected subset of bundles, where si\u2208 S. A\nrounding function \u0398is introduced and defined as:\n\u0398(x) =(\n0, if x>0.5\n1, otherwise(3.3)\nThis function is designed to introduce an equilibrium within the bundle set Sthrough\na process of bit inversion. Initially, the mean vector of Sis computed. Thereafter, the\nsubsequent bundle to be appended to Sis identified by rounding the components of\nthe mean vector to their closest bit values and subsequently inverting these bits. This\nmeans that an item in the bundle is notincluded if it is present in more than half of the\nbundles in S.\n(x\u2217)j=\u0398 \n1\ni\u2211\ns\u2208S(si)j!\nforj=1, 2, . . . , n (3.4)\nUsing Algorithm 3, an average occurrence of all items in the bundle set Sis achieved.\n14", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "e8655706-c5b1-407f-8a98-d5b7ac29e54c": {"__data__": {"id_": "e8655706-c5b1-407f-8a98-d5b7ac29e54c", "embedding": null, "metadata": {"page_label": "15", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nAlgorithm 3: GFFT(reverse)\nData: Amount of bundles n, Initial Sample Size k\nResult: Matrix Scontaining selected bundles and their values\nbk\u2190generate k bundles and values using uniform sampling\nS\u2190\u2205\nS\u2190bk\ncount\u21901\nwhile count\u2264n\u2212kdo\nm\u2190mean of all bundles in S\nx\u2217\u2190\u0398(m)\nS[k+count ]\u2190x\u2217\ncount \u2190count +1\nend\nS\u2190append value from bidder\nreturn S\n3.4 Greedy Active Learning on Input Values\nThe GALI (Yu and Kim 2010) was originally conceived as a technique for maximizing\ndiversity among data points in the input space. Given a set Sconsisting of bundles,\nthe objective is to identify the bundle x\u2217that is at the maximum distance from all the\nbundles in S. This active learning method explores the geometric solution, without\nthe need to learn a regression function. As a result, sampling becomes more efficient\nand stable, as it is not dependent on iterations of learning and validating a regression\nfunction. Wu, Lin, and Huang (2018) propose an algorithm to iterate over all unlabeled\nbundles in the available pool, the size of the bundle space in large auctions is growing\nexponentially, presenting a challenge. To address this, Estermann et al. (2023) modified\nthe method to be used in combinatorial auctions and used Integer Linear Programming\n(ILP) for calculating the distance in pseudo-polynomial time.\nFormal Definition: Given a bundle space Xand a set of sampled bundles S, where\nsi\u2208S, the objective is to identify the bundle x\u2217that is at the maximum distance from\nall the bundles in S. For each already sampled bundle s\u2208S, a subset H\u2286X\\Sis\ndefined, whose elements are at maximal distance from s.\nThe next bundle to query, where x\u2208His defined as:\nx\u2217=arg max\nx\u2208H\u2225x\u2212s\u2225\u2200s\u2208S (3.5)\nConstructing the set Hnecessitates calculating distances between each element of S\nand X, leading to exponential complexity. To avoid this, the subsequent optimization\n15", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "e79da3e8-c089-4d46-83a9-3d6d11bb9bae": {"__data__": {"id_": "e79da3e8-c089-4d46-83a9-3d6d11bb9bae", "embedding": null, "metadata": {"page_label": "16", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nproblem is solved for each s\u2208S:\narg max\nx\u2208X\u2225x\u2212s\u2225\ns.t.\u2225x\u2212s\u2225\u2264\r\rx\u2212s\u2032\r\r\u2200s\u2032\u2208S,s\u2032\u0338=s(3.6)\nThe core aim of this optimization is to identify a vector xthat maximizes its distance\nto a given vector swhile ensuring its proximity to all other vectors s\u2032in the set S\nis minimized. Since the formulation is non-linear, it is reformulated into a linear\noptimization problem:\narg max\nx\u2208Xm\n\u2211\nj=1xj+sj\u22122xjsj\ns.t.m\n\u2211\nj=1xj+sj\u22122xjsj\u2264m\n\u2211\nj=1xj+s\u2032\nj\u22122xjs\u2032\nj\u2200s\u2032\u2208S,s\u2032\u0338=s(3.7)\nFrom the computed bundles, the ILPselects the bundle that maximizes the distance\nmetric. The runtime is pseudo-polynomial, with the pseudo-code detailed in Algorithm\n4.\nAlgorithm 4: GALI\nData: Amount of bundles n\nResult: Matrix Scontaining selected bundles and their values\nb0\u2190generate random bundle\nS\u2190\u2205\nS[0]\u2190b0\ncount\u21901\nwhile count\u2264ndo\ndist x\u2190\u2205\nfori from 1to n\u22121do\nx\u2217=arg max x\u2208H\u2225x\u2212s\u2225compute using ILP Equation 3.7\ndist x\u2190x\u2217\nend\nS[count ]\u2190arg max dist x\ncount \u2190count +1\nend\nS\u2190append values for each bundle provided by bidder\nreturn S\n16", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "847be3d6-fd59-4397-9484-7ccf6da031bb": {"__data__": {"id_": "847be3d6-fd59-4397-9484-7ccf6da031bb", "embedding": null, "metadata": {"page_label": "17", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\n3.5 Greedy Active Learning on Output Values\nThe GALO is based on the similar idea as GALI . However, instead of calculating\ndistances between bundles (input values), GALO calculates distances between the\nreported values of bundles (output values).\nGiven a set Sconsisting of pairs of bundles and their respective values Y, the\nformulation is extended to include u(x), a value function associated with a bundle x.\nThe learning of this value function is performed separately from the linear optimization\nand requires a initial sampling strategy. UF was used for learning the output values.\nThe choice of machine learning algorithm to learn value function, be it linear or a\nfully-connected neural network, leads to variations in the implementation of the ILP\ndue to the different representations of the value function u(x).\nThe next bundle to query is determined by:\nx\u2217=arg max\nx\u2208H\u2225u(x)\u2212s\u2225 \u2200 y\u2208Y (3.8)\nTo circumvent the need to calculate this distance for every bundle in X, the following\noptimization problem is posed:\narg max\nx\u2208X|y\u2212u(x)|\ns.t.|y\u2212u(x)|\u2264\f\fy\u2032\u2212u(x)\f\f\u2200y\u2032\u2208Y,y\u2032\u0338=y(3.9)\nThis problem formulation requires adaption into a linear program due to the non-\nlinear constraints imposed by the Euclidean norm and the value function u(x). Sub-\nsequent sections discusses linear optimizations for both a Linear Model and a Neural\nNetwork Model. In this context, a parameter kis introduced, representing the number\nof bundles to initially sample using UFfor learning the value function. The pseudocode\nis provided in Algorithm 5.\n3.5.1 Greedy Active Learning on Output Values: Linear Model\nIn case of the Linear Model, the value function u(x)takes the form u(x) =wTx+w0,\nwhere ware the coefficients in Rmand w0is an intercept in R. The input bundle of x\nremains a vector {0, 1}m\nThe corresponding ILP serves as a linearized implementation of the previously\ndefined optimization problem. Additionally, Cis introduced as a large constant larger\nthan yoru(x)values, which ensures that the constraints are satisfiable and equivalent\nto Equation 3.9: Different linear models, such as Ordinary Least Squares, Ridge\nRegression, Non-negative Least Squares, were tested without observing any significant\nperformance difference. Ordinary Least Squares was selected as the default method for\n17", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "bfe5fbbb-99e9-4b9d-a6b9-397c7e2c853b": {"__data__": {"id_": "bfe5fbbb-99e9-4b9d-a6b9-397c7e2c853b", "embedding": null, "metadata": {"page_label": "18", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nAlgorithm 5: GALO\nData: Amount of bundles n, Initial Sample Size k, Machine Learning Model M\nResult: Matrix Scontaining selected bundles and their values\nbk\u2190generate k bundles and values using uniform sampling\nS\u2190\u2205\nS\u2190bk\ncount\u21901\nwhile count\u2264n\u2212kdo\nu(i)\u2190M(Sx,Sy)where Sxare bundle and Syare values\ndist x\u2190\u2205\niterations =len(S)\nfori from 0to iterations do\nx\u2217=arg max x\u2208H\u2225x\u2212s\u2225compute using ILP Equation 3.9\ndist x\u2190x\u2217\nend\nS[k+count ]\u2190arg max dist x\nfor bundle provided by S[k+count ]\u2190append value from bidder\ncount \u2190count +1\nend\nreturn S\n18", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "6eaadc21-af5a-4c43-80a9-62b866c686a4": {"__data__": {"id_": "6eaadc21-af5a-4c43-80a9-62b866c686a4", "embedding": null, "metadata": {"page_label": "19", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nGreedy Active Learning on Output Values (linear) ( GALO(linear) ) due to its simplicity\nand computational efficiency.\narg max\nx\u2208Xr\ns.t. y\u2212u(x)\u2264r,\nu(x)\u2212y\u2264r,\ny\u2032\u2212u(x) +C\u00b7by\u2032\u2265r,\nu(x)\u2212y\u2032+C\u00b7(1\u2212by\u2032)\u2265r,\n\u2200y\u2032\u2208Y,\nby\u2032\u2208 {0, 1} \u2200 y\u2032\u2208Y,\nr\u2208R(3.10)\n3.5.2 Greedy Active Learning on Output Values: Neural Network\nA neural network notation to approximate a value function u(x)is defined as:\n\u2022K={0,. . .,K}denotes the set of layers in the network(input and output layer\nincluded).\n\u2022kis an index representing a specific layer in K.\n\u2022dkdenotes the dimension of layer k.\n\u2022bkis the bias term for layer k.\n\u2022Wkis the weight matrix for layer k.\n\u2022okis the output of layer k, defined as ok=ReLU (Wk\u22121\u00b7ok\u22121+bk\u22121).\nSubsequently, a few constraint vectors are introduced to ensure that the network\noutput is equal to the value function: u(x):zk,yk,qk, all in dkdimension. zkand qkare\ncontinuous constrains, whereas ykis a binary constraint. L is used as a large constant,\nso for every z\u2208zk,z<Land q\u2208yk,y<L. The objective of the linear optimization\nis to minimize the distance between the output of the network and the value function\nu(x)and achieve z0=o0=x\u2217\n19", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "b6e07977-2079-4df3-95ac-4a99a1f2665c": {"__data__": {"id_": "b6e07977-2079-4df3-95ac-4a99a1f2665c", "embedding": null, "metadata": {"page_label": "20", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\narg maxx\u2208Xr\ns.t. y\u2212zK\u2264r\nzK\u2212y\u2264r\ny\u2032\u2212zK+C\u00b7by\u2032\u2265r\nzK\u2212y\u2032+C\u00b7(1\u2212by\u2032)\u2265r\n\u2200y\u2032\u2208Y,by\u2032\u2208 {0, 1}\nr\u2208R\nz0=x\nzk\u2212qk=Wk\u22121\u00b7zk\u22121+bk\u22121\n0\u2264zk\u2264yk\u00b7L\n0\u2264qk\u2264(1\u2212yk)\u00b7L\nyk\u2208 {0, 1}dk\n\u2200k\u2208 {1, . . . , K}(3.11)\nThe following picture provides a visual representation how the neural network is\nused in Greedy Active Learning on Output Values (Neural Network) (GALO(NN)).\nItem #1\nItem #2\nItem #3\nItem #4Predicted User Value(K\u22121)\u00d7zk\nHidden Layersz0Input Layer zKOutput Layer\nWhile the initial experimental results for the GALO(NN) algorithm did not meet\nour performance benchmarks, the approach itself holds considerable promise. The\ncore innovation behind GALO(NN) offers a new perspective on solving complex\nproblems. Although the current implementation struggles with efficiency in MLCA ,\nthese challenges are likely surmountable with further research and optimization. The\nfoundational principles of GALO(NN) offer a fertile ground for future improvements\nand adaptations, making it a candidate worth further investigation. For example, the\n20", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "39e728ad-0d5d-4ecc-912c-114d1339ac34": {"__data__": {"id_": "39e728ad-0d5d-4ecc-912c-114d1339ac34", "embedding": null, "metadata": {"page_label": "21", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "3 Active Learning\nGALO(NN) algorithm could be adapted to use a different activation functions or deep\nneural networks with more layers or neurons.\nThe claims of this paper for the transformation of optimization problems of GALI\nand GALO into ILP are supported by proofs of Estermann et al. (2023).\n21", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "57974253-9413-4595-a6ca-4deb47830abd": {"__data__": {"id_": "57974253-9413-4595-a6ca-4deb47830abd", "embedding": null, "metadata": {"page_label": "22", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\n4.1 Experiment setup\nThe experimental evaluations were conducted on a computing cluster running the\nUbuntu 20.04 operating system. The cluster\u2019s hardware specifications include an\nNVIDIA GeForce RTX 2080 Ti graphics card and an Intel(R) Xeon(R) Silver 4116 CPU\nthat operates at a base speed of 2.10 GHz, complemented by 12 GB of RAM.\nThe implementation was done using Python version 3.6.13. For solving MIP and\nGALI optimization problems, we used IBM ILOG CPLEX Optimization Studio V12.8.0\n(Cplex 2009). We interfaced with CPLEX using the docplex 2.4.61. For training the\nGALO models, we opted for Gurobi version 9.1.2 due to its superior parallelization\ncapabilities. Linear regression models were implemented using with Scikit-learn version\n0.24.2 and PyTorch version 1.8.0.\n4.2 Spectrum Auction Test Suite\nCombinatorial Auction Test Suite ( CATS ) (Leyton-Brown, Pearson, and Shoham 2000)\nstands as one of the seminal combinatorial auctions test suites for testing real-world\nscenarios. Despite its significant contributions to many research endeavors, CATS does\nnot offer specific features for simulating spectrum auctions as they were not designed\nto do so. Moreover, CATS lacks specific features for research applications, such as a\npossibility to assign a value for a specific bundle.\nOn the other hand, Spectrum Auction Test Suite ( SATS ) v0.8.1 (Weiss, Lubin, and\nSeuken 2017) serves as the specialized suite for the combinatorial auctions, introducing a\nlifelike model of spectrum auctions. A notable feature is the integrated MIP formulation\nfor the WDP , eliminating the need for additional overhead for this study. The MIP\nformulation encodes the values for a substantial speed up in performance for solving\nWDP . The suite differentiates bidders as local, regional or national players. National\nplayers generally target all regions, while regional players tend to prioritize their\nregions. Local bidders exclusively value items in their region, meaning they have zero\nutility for items outside their region. Additionally, SATS incorporates domain-specific\nknowledge such as bandwidth, population per region, quality of service metrics.\n22", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "60ac34cf-5d0b-4401-a4d4-62970ea9ccc7": {"__data__": {"id_": "60ac34cf-5d0b-4401-a4d4-62970ea9ccc7", "embedding": null, "metadata": {"page_label": "23", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nThree auction models from SATS \u2014GSVM ,LSVM , and MRVM \u2014 have been em-\nployed for the experiments. GSVM encompasses 6 regional bidders and 1 national\nbidder competing for bidding over 18 items with no synergistic values between item\ncombinations. LSVM involves 5 regional bidders and 1 national bidder bidding for 18\nitems. For this type of auction, there is complementary effect in having combinations\nof items. MRVM is the most intricate, compromising 4 regional bidders, 3 national\nbidders and 3 local bidders, vying for 98 items. MRVM also captures the geographic\nand frequency parameters to determine utility for a specific bidder per unique bundle.\n4.3 Hyperparameters\nTable 4.1: Neural Network Architectures. Numbers inside brackets describe the number\nof neurons in hidden layers. The input layer is the same size as the number\nof items in the auction and the output is 1.\nBidder Type GSVM LSVM MRVM\nLocal Bidder N/A N/A [16,16]\nRegional Bidder [32,32] [32,32] [16,16]\nNational Bidder [10,10] [10,10,10] [16,16]\nWeissteiner and Seuken (2020) conducted an in-depth study that proposed and rigor-\nously tested various deep neural network architectures tailored for different types of\nauctions. Although the optimization of network architecture is undeniably crucial for\nperformance improvement, the primary focus of this study diverges from this aspect.\nInstead, the research is oriented toward the effective integration of active learning\nalgorithms with existing architectures. Therefore, for the purposes of this study, the\nconfigurations and architectures validated in previous studies (Estermann et al. 2023)\nserve as the experimental baseline. Neural network architecture for the NextQueries is\ndescribed in Table 4.1. Each auction domain has almost the same MIP and Neural Net-\nwork ( NN) hyperparameters, which are listed in Table 4.2. The only difference is in the\nMRVM domain, where the Scaler is set to MinMaxScaler(copy=True, feature_range=(0,\n500)) and Regularization Type are L1 and L2.\n23", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "9561ff46-2af2-4aef-aaa5-f41590568924": {"__data__": {"id_": "9561ff46-2af2-4aef-aaa5-f41590568924", "embedding": null, "metadata": {"page_label": "24", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nTable 4.2: Hyperparameter Settings Auctions\nParameter\nNN Hyperparameter Settings\nRegularization Type L2\nRegularization Factor 1 \u00d710\u22125\nLearning Rate 0.01\nDropout True\nDropout Rate 0.05\nMIP Hyperparameters Settings\nL 3000\nMip_bounds_tightening IA\nsample_weight False\nScaler False\nwarm_start False\nSeed Instances 0 - 20\n24", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "06750efa-f508-4023-8e00-e516411849cd": {"__data__": {"id_": "06750efa-f508-4023-8e00-e516411849cd", "embedding": null, "metadata": {"page_label": "25", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nTable 4.3: Active Learning Hyperparameter Settings. kis the number of bundles to\nbe sampled with UF, c0is the number of initial bundles sampled by active\nlearning strategy and ceis the number of bundles to be sampled in each\niteration by NextQueries.\nModel Sampling Technique k c 0ce\nGSVM UF N/A 30 20\nGFFT N/A 30 20\nGFFT (reverse) 20 10 20\nGALI N/A 30 20\nGALO (linear) 20 10 20\nLSVM UF N/A 40 10\nGFFT N/A 40 10\nGFFT (reverse) 30 10 10\nGALI N/A 40 10\nGALO (linear) 30 10 10\nMRVM UF N/A 40 30\nGFFT (reverse) 30 10 30\nGALI N/A 40 30\nGALO (linear) 30 10 30\n4.4 Comparison\nThe study compares the efficiency and runtime of MLCA based on DNN .UF,GFFT ,\nGFFT(reverse) ,GALI and GALO(linear) are used for the GSVM and LSVM domains.\nGFFT is not applied to the MRVM domain due to a substantial amount of time to\nthe computational intensity required to handle the 298possible bundles. This would\nrequire O(n2)computations and O(n2)distance calculations. GALO(NN) has deemed\nnot effective in our experiments. From now on we refer to GALO(linear) asGALO , if\nnot stated otherwise. Increasing the number of threads improves the runtime of the\nGALO and GALI algorithms by a few minutes, as Gurobi allows for parallelization.\nThe runtime of each active learning technique is included into the total runtime. Initial\nbundles, however, still influence the consequent iterations of auction models as they are\nused for the MLCA WDP MIP solver. Throughout the process of collecting experiments,\nwe have experienced a few problems in parallelizing lots of instances at the same time.\nThe reason behind it is that the MLCA solver was designed to use all available threads.\nThis means that the solver cannot be run in parallel, as it will cause substantial decrease\nof runtime. To showcase runtime we use boxplots: a boxplot is a graphical representation\n25", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "af97a169-5f69-4b9e-b3f3-f51c1e2cdff1": {"__data__": {"id_": "af97a169-5f69-4b9e-b3f3-f51c1e2cdff1", "embedding": null, "metadata": {"page_label": "26", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nused for depicting the distribution and spread of a dataset. The box itself represents\nthe interquartile range (IQR), showing the 25th percentile (Q1) and the 75th percentile\n(Q3). The horizontal line within the box indicates the median of the data. Whiskers\nextend from the box to show the range of the data. Outliers are plotted individually.\n4.4.1 GSVM\nFirst, we will discuss the outcomes obtained from applying active learning techniques\nto the GSVM auction domain. We observe a notable increase in efficiency for both\nGFFT(reverse) and GALI . Given that GSVM is a relatively straightforward auction,\nthe efficiency rate closely approaches 100% . When compared with UF, the efficiency\ndemonstrates an overall increment of approximately 2%. In the case of GALO , a\nmodest improvement of around 0.5% is observed. UFand GFFT exhibit nearly identical\nefficiencies, as illustrated in Figure 4.1. Despite the high computational complexity\nassociated with the GFFT method, it does not yield a significant improvement in\nefficiency for the selected hyperparameters.\nIt is evident that there is an overall increase in runtime for all active learning\nalgorithms when compared to UF. This can be attributed to the initial computational\noverhead required by these algorithms. Based on the results obtained from the sampling\nprocess, GALI exhibits a notably low runtime. This can be ascribed to the algorithm\u2019s\nlow computational complexity, as it does not necessitate the calculation of distances\nbetween sets of bundles. Upon examination of the data, GALI emerges as a superior\nactive learning method for the GSVM auction domain.\n26", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "44ed80c9-987f-4af5-a7c5-afd220fe7481": {"__data__": {"id_": "44ed80c9-987f-4af5-a7c5-afd220fe7481", "embedding": null, "metadata": {"page_label": "27", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nFigure 4.1: Efficiency of a GSVM auction\nFigure 4.2: Runtime of a GSVM auction27", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "fd08b94c-53cf-46c3-8d1e-a5acb9b69ed3": {"__data__": {"id_": "fd08b94c-53cf-46c3-8d1e-a5acb9b69ed3", "embedding": null, "metadata": {"page_label": "28", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nAdditionally, we discuss the efficiency per round for each active learning algorithm,\na metric that facilitates the observation of efficiency rate progression for MLCA . This\nis crucial as the initial bundles exert influence on all subsequent auction mechanism\niterations. Given the hyperparameters adopted in this paper, the GSVM auction domain\nundergoes three iterations. The initial efficiency of the first round is computed based on\nbundle profiles initialized by the active learning algorithms. Our observations indicate\nthat GFFT(reverse) exhibits above-average efficiency in the initial round. The algorithm\nbalances out the items not included in the initially sampled bundles and maintains high\nefficiency, only falling behind GALI in the final round. Although GALO commences\nwith suboptimal efficiency, it experiences a significant uptick in subsequent rounds.\nAltering the model architecture to increase the number of rounds and employing GALO\ncould yield promising results.\nFigure 4.3: Efficiency per round of a GSVM auction\n4.4.2 LSVM\nIn contrast to the GSVM auction domain, the LSVM domain presents greater complex-\nity, resulting in divergent outcomes among the active learning algorithms. This auction\nundergoes only two rounds of iterations due to the presence of 40 initial instances and\n28", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "cfb71187-a633-40ad-bb5d-583d8a479a65": {"__data__": {"id_": "cfb71187-a633-40ad-bb5d-583d8a479a65", "embedding": null, "metadata": {"page_label": "29", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nan additional 10 for the elicitation algorithm in MLCA . This characteristic makes the\ndomain more reliant on the efficiency of the initial round and less so on subsequent\nrounds. As evident in Figure 4.4, all active learning algorithms surpass UFin perfor-\nmance. Both GFFT and GALI yield the highest efficiencies, with GFFT having a slight\nedge. GALO demonstrates a moderate efficiency increase, whereas GFFT(reverse) falls\nin the intermediate range. Interestingly, GFFT , despite its lackluster performance in the\nGSVM domain, exhibits a significant efficiency boost in the LSVM domain.\nFigure 4.4: Efficiency of a LSVM auction\nFigure 4.5 presents an empirical comparison of runtime across five distinct algorithms\nin the LSVM domain. The results are more uniform compared to those in the GSVM\ndomain. All active learning algorithms exhibit slightly higher runtimes than the UF\nmethod. However, GFFT(reverse) emerges as the most time-efficient among the active\nlearning algorithms, followed closely by the others. GALI presents some outliers that\nelevate its runtime, but its mean time remains lower than that of GALO . If runtime and\n29", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "7c1d7cee-33b1-423e-b59f-022bae65c6e6": {"__data__": {"id_": "7c1d7cee-33b1-423e-b59f-022bae65c6e6", "embedding": null, "metadata": {"page_label": "30", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nefficiency over a limited number of rounds are priorities for the auction, GFFT(reverse)\nis the optimal choice. On the other hand, for auctions anticipated to run over numerous\nrounds, GALI orGALO are more suitable options, as evidenced by its performance in\nthe GSVM domain.\nFigure 4.5: Runtime of a LSVM auction\nBased on the empirical evaluations presented in Figure 4.6, GFFT(reverse) excels in\nperformance during the initial round, surpassing all other algorithms. Conversely, both\nGALI and GFFT demonstrate their efficacy in the subsequent iteration, achieving the\nhighest efficiency among the tested algorithms.\n30", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "300fd77f-c1b3-41ed-a3f4-c3a04c11bbdc": {"__data__": {"id_": "300fd77f-c1b3-41ed-a3f4-c3a04c11bbdc", "embedding": null, "metadata": {"page_label": "31", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nFigure 4.6: Efficiency per round of a LSVM auction\n4.4.3 MRVM\nFor the largest domain under consideration, we evaluate both the efficiency and\nefficiency-per-round metrics. Due to the need for parallelization across numerous\ninstances, the runtime results exhibit non-consistent behavior as we have used multiple\nparallelization tools for some instances. GFFT method is not used in this auction\ndomain, as it has an exponential runtime. In the MRVM domain, the differences in\nefficiency are less pronounced; however, a modest improvement is still observable.\nGALO exhibits the highest efficiency, followed by GFFT(reverse) and GALI , while UF\nperforms the worst. This can be attributed to the higher number of items and bidders\nin the MRVM domain, complicating the exploitation of geometric structures in output\nsets. One of the top-performing algorithms, GFFT(reverse) , maintains their standings,\nconsistent with outcomes from previous domains. Regarding efficiency per round,\nGFFT(reverse) starts strong, in line with its performance in other domains. GALI begins\nat a lower efficiency but manages to catch up in subsequent rounds. GALO exhibits\na surprising result for a large auction domain. This can be attributed to the fact that\nthe algorithm is not as reliant on the bundles as other algorithms. GALO is more\ndependent on the values of bundles, giving it an edge in domains, where preferences\n31", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "c2f0b016-badd-4ed6-9f10-54d0f7d2be45": {"__data__": {"id_": "c2f0b016-badd-4ed6-9f10-54d0f7d2be45", "embedding": null, "metadata": {"page_label": "32", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nFigure 4.7: Efficiency of a MRVM auction\nare hard to elicit. Other algorithms are using distance between groups of bundles to\nfind the most informative bundles, which is not as effective in the MRVM domain.\n32", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "edf510ba-77c9-4982-a7c2-0542c23fc9e4": {"__data__": {"id_": "edf510ba-77c9-4982-a7c2-0542c23fc9e4", "embedding": null, "metadata": {"page_label": "33", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "4 Results\nFigure 4.8: Efficiency per round of a MRVM auction\n33", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "38860cdc-85a9-4b8a-8ac3-91ab8c954468": {"__data__": {"id_": "38860cdc-85a9-4b8a-8ac3-91ab8c954468", "embedding": null, "metadata": {"page_label": "34", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "5 Conclusion\nIn this work, we have introduced a suite of active learning algorithms tailored for the\nMLCA framework and elucidated their impact on augmenting the efficiency of combi-\nnatorial auctions. Through experimental evaluation, we have furnished contributions\nto the field of combinatorial auction research. We improved the results of MLCA by\nusing active learning algorithms. On the technical front, our implementation serves as\na robust foundation for active learning methods aimed at enhancing auction efficiency.\nFuture Prospects and Extensions: Our research opens up multiple avenues for\nfurther inquiry and refinement in the active learning landscape:\n\u2022Given the extensible nature of our implementation, the platform is amenable\nto the integration and evaluation of a broad array of active learning techniques\ntailored for auction labeling tasks.\n\u2022Algorithms such as GALO(NN) and GALO(linear) hold significant promise. Fu-\nture work could delve into varying architectures of neural networks and types of\nlinear regressions to optimize these algorithms further.\n\u2022The hyperparameter space remains largely unexplored, offering opportunities\nfor in-depth investigation, particularly concerning the sample size for each active\nlearning algorithm.\nOur findings lay the groundwork for subsequent research efforts, offering a robust\nmethodology for enhancing the efficiency of complex auction mechanisms.\n34", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "3e7963bb-28e8-48db-855e-9660e11fcf14": {"__data__": {"id_": "3e7963bb-28e8-48db-855e-9660e11fcf14", "embedding": null, "metadata": {"page_label": "35", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Abbreviations\nMRVM Multi-Region Value Model\nLSVM Linearly Correlated Value Model\nGSVM Generalized Value Model\nGALI Greedy Active Learning on Input Values\nGALO Greedy Active Learning on Output Values\nGALO(linear) Greedy Active Learning on Output Values (linear)\nGALO(NN) Greedy Active Learning on Output Values (Neural Network)\nGFFT Greedy Farthest-First Traversal\nGFFT(reverse) Greedy Farthest-First Traversal (reverse)\nUF Uniform Sampling\nMIP Mixed-Integer Programming\nWDP Winner Determination Problem\n35", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "6f9a237d-6206-4c2b-a5b1-ebbbffbe3a34": {"__data__": {"id_": "6f9a237d-6206-4c2b-a5b1-ebbbffbe3a34", "embedding": null, "metadata": {"page_label": "36", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Abbreviations\nNN Neural Network\nVCG Vickrey-Clarke-Groves auction\nMLCA Machine Learning Combinatorial Auction\nSVR Support Vector Regression\nDNN Deep Neural Network\nILP Integer Linear Programming\nCATS Combinatorial Auction Test Suite\nSATS Spectrum Auction Test Suite\n36", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "a6a0e395-f36c-42bd-8600-a9990fcfd488": {"__data__": {"id_": "a6a0e395-f36c-42bd-8600-a9990fcfd488", "embedding": null, "metadata": {"page_label": "37", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "List of Algorithms\n1 Machine Learning-powered Combinatorial Auction (MLCA) . . . . . . . 10\n2 GFFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3 GFFT(reverse) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n4 GALI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5 GALO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n37", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "5f15be51-a119-46b9-a174-ac5c9030915a": {"__data__": {"id_": "5f15be51-a119-46b9-a174-ac5c9030915a", "embedding": null, "metadata": {"page_label": "38", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "List of Figures\n4.1 Efficiency of a GSVM auction . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.2 Runtime of a GSVM auction . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.3 Efficiency per round of a GSVM auction . . . . . . . . . . . . . . . . . . . 28\n4.4 Efficiency of a LSVM auction . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.5 Runtime of a LSVM auction . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.6 Efficiency per round of a LSVM auction . . . . . . . . . . . . . . . . . . . 31\n4.7 Efficiency of a MRVM auction . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.8 Efficiency per round of a MRVM auction . . . . . . . . . . . . . . . . . . 33\n38", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "8b6a62ca-f15d-4c3e-9ac8-a418e9cebc6f": {"__data__": {"id_": "8b6a62ca-f15d-4c3e-9ac8-a418e9cebc6f", "embedding": null, "metadata": {"page_label": "39", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "List of Tables\n4.1 Neural Network Architectures. Numbers inside brackets describe the\nnumber of neurons in hidden layers. The input layer is the same size as\nthe number of items in the auction and the output is 1. . . . . . . . . . . 23\n4.2 Hyperparameter Settings Auctions . . . . . . . . . . . . . . . . . . . . . . 24\n4.3 Active Learning Hyperparameter Settings. kis the number of bundles\nto be sampled with UF, c0is the number of initial bundles sampled by\nactive learning strategy and ceis the number of bundles to be sampled\nin each iteration by NextQueries. . . . . . . . . . . . . . . . . . . . . . . . 25\n39", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "9b892026-c13c-4acd-84f9-435e34712be4": {"__data__": {"id_": "9b892026-c13c-4acd-84f9-435e34712be4", "embedding": null, "metadata": {"page_label": "40", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Bibliography\nAusubel, Lawrence M., and Oleg Baranov. 2017. A Practical Guide to the Combinatorial\nClock Auction. The Economic Journal 127 (605): F334\u2013F350. issn: 0013-0133, accessed\nAugust 24, 2023. https://www.jstor.org/stable/45022990.\nBichler, Martin, Pasha Shabalin, and J\u00fcrgen Wolf. 2013. Do core-selecting Combinato-\nrial Clock Auctions always lead to high efficiency? An experimental analysis of\nspectrum auction designs. Experimental Economics 16 (4): 511\u2013545. issn : 1386-4157,\naccessed September 10, 2023. https://econpapers.repec.org/article/kapexpeco/v_\n3a16_3ay_3a2013_3ai_3a4_3ap_3a511-545.htm.\nBlum, Avrim, Jeffrey Jackson, Tuomas Sandholm, and Martin Zinkevich. 2003. Pref-\nerence Elicitation and Query Learning. The Journal of Machine Learning Research 5\n(July): 649\u2013667. issn : 978-3-540-40720-1. https://doi.org/10.1007/978-3-540-45167-\n9_3.\nBrero, Gianluca, and S\u00e9bastien Lahaie. 2018. A bayesian clearing mechanism for combinato-\nrial auctions. arXiv: 1712.05291 [cs.GT] .\nBrero, Gianluca, S\u00e9bastien Lahaie, and Sven Seuken. 2019. Fast iterative combinatorial\nauctions via bayesian learning. arXiv: 1809.05340 [cs.GT] .\nBrero, Gianluca, Benjamin Lubin, and Sven Seuken. 2021. Machine learning-powered\niterative combinatorial auctions. arXiv: 1911.08042 [cs.GT] .\nBrewer, Paul J. 1999. Decentralized computation procurement and computational\nrobustness in a smart market [in en]. Economic Theory 13, no. 1 (January): 41\u201392.\nissn: 1432-0479, accessed August 24, 2023. https://doi.org/10.1007/s001990050242.\nhttps://doi.org/10.1007/s001990050242.\nCaplice, Christopher George. 1996. An optimization based bidding process : a new\nframework for shipper-carrier relationships [in eng]. PhD diss., Massachusetts\nInstitute of Technology. Accessed August 24, 2023. https://dspace.mit.edu/\nhandle/1721.1/10846.\n40", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "89dcea20-20e3-4ca7-b886-9b5cf3a4b8b4": {"__data__": {"id_": "89dcea20-20e3-4ca7-b886-9b5cf3a4b8b4", "embedding": null, "metadata": {"page_label": "41", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Bibliography\nClarke, Edward. 1971. Multipart pricing of public goods. Public Choice 11 (1): 17\u201333.\nissn : 0048-5829, accessed August 30, 2023. https://econpapers.repec.org/article/\nkappubcho/v_3a11_3ay_3a1971_3ai_3a1_3ap_3a17-33.htm.\nConitzer, Vincent, and Tuomas Sandholm. 2002. Complexity of mechanism design. arXiv:\ncs/0205075 [cs.GT] .\n. 2004. Self-interested automated mechanism design and implications for optimal\ncombinatorial auctions. In Proceedings of the 5th ACM conference on Electronic com-\nmerce, 132\u2013141. EC \u201904. New York, NY, USA: Association for Computing Machinery,\nMay. isbn : 9781581137712, accessed September 13, 2023. https://doi.org/10.1145/\n988772.988793. https://doi.org/10.1145/988772.988793.\nCplex, IBM ILOG. 2009. V12. 1: user\u2019s manual for cplex. International Business Machines\nCorporation 46 (53): 157.\nDuetting, Paul, Zhe Feng, Harikrishna Narasimhan, David Parkes, and Sai Srivatsa\nRavindranath. 2019. Optimal Auctions through Deep Learning [in en], 1706\u20131715.\nPMLR, May. Accessed September 13, 2023. https://proceedings.mlr.press/v97/\nduetting19a.html.\nEstermann, Benjamin, Stefan Kramer, Roger Wattenhofer, and Ye Wang. 2023. Deep\nLearning-Powered Iterative Combinatorial Auctions with Active Learning. In Pro-\nceedings of the 2023 International Conference on Autonomous Agents and Multiagent\nSystems, 2919\u20132921. AAMAS \u201923. Richland, SC: International Foundation for Au-\ntonomous Agents / Multiagent Systems, May. isbn : 9781450394321, accessed\nAugust 24, 2023.\nGroves, Theodore. 1973. Incentives in Teams. Econometrica 41 (4): 617\u2013631. issn : 0012-\n9682, accessed August 30, 2023. https://doi.org/10.2307/1914085. https://www.\njstor.org/stable/1914085.\nHershberger, J., and S. Suri. 2001. Vickrey prices and shortest paths: what is an edge\nworth? In Proceedings 42nd IEEE Symposium on Foundations of Computer Science,\n252\u2013259. ISSN: 1552-5244. October. https://doi.org/10.1109/SFCS.2001.959899.\nLahaie, S\u00e9bastien, and Benjamin Lubin. 2019. Adaptive-Price Combinatorial Auctions.\nInProceedings of the 2019 ACM Conference on Economics and Computation, 749\u2013750.\nEC \u201919. New York, NY, USA: Association for Computing Machinery, June. isbn :\n9781450367929, accessed September 13, 2023. https://doi.org/10.1145/3328526.\n3329615. https://doi.org/10.1145/3328526.3329615.\n41", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "ddfe7b29-c37e-47d4-8d53-71756a6b1b83": {"__data__": {"id_": "ddfe7b29-c37e-47d4-8d53-71756a6b1b83", "embedding": null, "metadata": {"page_label": "42", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Bibliography\nLahaie, S\u00e9bastien, and David C. Parkes. 2004. Applying learning algorithms to prefer-\nence elicitation. In Proceedings 5th ACM Conference on Electronic Commerce (EC-2004),\nNew York, NY, USA, May 17-20, 2004, edited by Jack S. Breese, Joan Feigenbaum,\nand Margo I. Seltzer, 180\u2013188. ACM. https://doi.org/10.1145/988772.988800.\nLeyton-Brown, Kevin, Mark Pearson, and Yoav Shoham. 2000. Towards a universal\ntest suite for combinatorial auction algorithms. In Proceedings of the 2nd ACM\nconference on Electronic commerce, 66\u201376. EC \u201900. New York, NY, USA: Association\nfor Computing Machinery, October. isbn : 9781581132724, accessed August 23, 2023.\nhttps://doi.org/10.1145/352871.352879. https://dl.acm.org/doi/10.1145/352871.\n352879.\nMishra, Debasis, and David C. Parkes. 2007. Ascending price Vickrey auctions for\ngeneral valuations. Journal of Economic Theory 132, no. 1 (January): 335\u2013366. issn :\n0022-0531, accessed August 30, 2023. https://doi.org/10.1016/j.jet.2005.09.004.\nhttps://www.sciencedirect.com/science/article/pii/S0022053105001985.\nPark, Sung Ho, and Seoung Bum Kim. 2020. Robust expected model change for active\nlearning in regression [in en]. Applied Intelligence 50, no. 2 (February): 296\u2013313. issn:\n0924-669X, 1573-7497, accessed August 24, 2023. https://doi.org/10.1007/s10489-\n019-01519-z. http://link.springer.com/10.1007/s10489-019-01519-z.\nRassenti, S. J., V . L. Smith, and R. L. Bulfin. 1982. A Combinatorial Auction Mechanism\nfor Airport Time Slot Allocation. The Bell Journal of Economics 13 (2): 402\u2013417.\nissn : 0361-915X, accessed August 24, 2023. https://doi.org/10.2307/3003463.\nhttps://www.jstor.org/stable/3003463.\nScheffel, Tobias, Georg Ziegler, Martin Bichler, and Riko Jacob. 2012. On the Impact\nof Cognitive Limits in Combinatorial Auctions: An Experimental Study in the\nContext of Spectrum Auction Design. Experimental Economics 15 (December). https:\n//doi.org/10.1007/s10683-012-9321-0.\nTaylor, Gregory. 2013. Oil in the Ether: A Critical History of Spectrum Auctions in Canada\n[in en]. Technical report 2473272. Rochester, NY, January. Accessed August 24, 2023.\nhttps://doi.org/10.2139/ssrn.2473272. https://papers.ssrn.com/abstract=2473272.\nVickrey, William. 1961. Counterspeculation, Auctions, and Competitive Sealed Tenders.\nThe Journal of Finance 16 (1): 8\u201337. issn : 0022-1082, accessed August 30, 2023. https:\n//doi.org/10.2307/2977633. https://www.jstor.org/stable/2977633.\n42", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}, "d4c2d851-cae8-4d8f-aa47-20bca1fb197b": {"__data__": {"id_": "d4c2d851-cae8-4d8f-aa47-20bca1fb197b", "embedding": null, "metadata": {"page_label": "43", "file_name": "document.pdf", "file_path": "/home/artem/programming/makethon-nlp/data/document.pdf", "file_type": "application/pdf", "file_size": 852564, "creation_date": "2024-04-26", "last_modified_date": "2024-04-26"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {}, "text": "Bibliography\nVries, Sven de, James Schummer, and Rakesh V . Vohra. 2007. On ascending Vickrey\nauctions for heterogeneous objects. Journal of Economic Theory 132 (1): 95\u2013118. issn :\n0022-0531, accessed August 30, 2023. https://econpapers.repec.org/article/\neeejetheo/v_3a132_3ay_3a2007_3ai_3a1_3ap_3a95-118.htm.\nWeiss, Michael, Benjamin Lubin, and Sven Seuken. 2017. SATS: A Universal Spectrum\nAuction Test Suite. In Proceedings of the 16th Conference on Autonomous Agents and\nMultiAgent Systems, 51\u201359. AAMAS \u201917. Richland, SC: International Foundation\nfor Autonomous Agents / Multiagent Systems, May. Accessed August 23, 2023.\nWeissteiner, Jakob, Jakob Heiss, Julien Siems, and Sven Seuken. 2023. Bayesian Optimization-\nBased Combinatorial Assignment [in en]. Proceedings of the AAAI Conference on\nArtificial Intelligence 37, no. 5 (June): 5858\u20135866. issn: 2374-3468, accessed August 24,\n2023. https://doi.org/10.1609/aaai.v37i5.25726. https://ojs.aaai.org/index.php/\nAAAI/article/view/25726.\nWeissteiner, Jakob, and Sven Seuken. 2020. Deep Learning-powered Iterative Com-\nbinatorial Auctions. ArXiv:1907.05771 [cs], Proceedings of the AAAI Conference on\nArtificial Intelligence 34, no. 02 (April): 2284\u20132293. issn : 2374-3468, 2159-5399, ac-\ncessed August 23, 2023. https://doi.org/10.1609/aaai.v34i02.5606. http://arxiv.\norg/abs/1907.05771.\nWeissteiner, Jakob, Chris Wendler, Sven Seuken, Ben Lubin, and Markus P\u00fcschel. 2022.\nFourier Analysis-based Iterative Combinatorial Auctions. In Proceedings of the Thirty-\nFirst International Joint Conference on Artificial Intelligence, 549\u2013556. ArXiv:2009.10749\n[cs]. July. Accessed August 24, 2023. https://doi.org/10.24963/ijcai.2022/78.\nhttp://arxiv.org/abs/2009.10749.\nWu, Dongrui. 2018. Pool-based sequential active learning for regression. arXiv: 1805.04735\n[cs.LG] .\nWu, Dongrui, Chin-Teng Lin, and Jian Huang. 2018. Active learning for regression using\ngreedy sampling. arXiv: 1808.04245 [cs.LG] .\nYu, Hwanjo, and Sungchul Kim. 2010. Passive Sampling for Regression. In 2010 IEEE\nInternational Conference on Data Mining, 1151\u20131156. ISSN: 2374-8486. December.\nhttps://doi.org/10.1109/ICDM.2010.9.\n43", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "Document"}, "__type__": "4"}}, "docstore/metadata": {"2c78e2df-0fc2-4f9d-93ca-08dc4ce41c8e": {"doc_hash": "7540f3e852821c71ca1be845961a1cb58a0e47ba6481713c4fcebec75d524ad5"}, "314d4bf7-8bc2-489e-bcd8-f0d51d466f5a": {"doc_hash": "d4e7c3fef7237d8c81849fe9ac70990022993fa41d5cfa6bfd3bd5eedfe1b615"}, "d50f3577-c540-4add-a2fa-59f70aae1a03": {"doc_hash": "eef7d5f826da6bdecc98167adfa0dbec1cbcc2ce6c4730be7771b02d8b64fec9"}, "039374eb-cff8-4c17-a8ae-48feede2253e": {"doc_hash": "1946f9457d456e7beeaab5dfb920bb18c14ffaa3e5736619d6ed7526d0c4dec7"}, "117fa057-7f88-410f-992c-18219faba31f": {"doc_hash": "731250bf758601cad4ff870ce69181257a7463668fd66fecd2c6b1ee0b5b16e3"}, "7a3d2470-9999-47b2-98ab-0918363e87db": {"doc_hash": "6c71b5d091b17df763d03dc8de5447cc282b29bf965b7c2271a649d32d188ba2"}, "6b87f6e1-dc86-416f-bfaf-ac1eaacd8679": {"doc_hash": "a19f24ca76f6869487812a98d507e988e884ca2c0570bc4b25eba01b839f7d7c"}, "608b7309-18ab-4a90-bdb7-a14abb92881b": {"doc_hash": "7b6b6684916483f38f521ce9e227ce8e097f1ca79442dc33214549aa86a5940e"}, "01bac0bd-9224-4b2c-b984-15118458a84a": {"doc_hash": "d73f79c23d658479f6614f5988179f0821f9e246a38c05d835aa3ccb12c4a738"}, "e9337a48-bf37-4ee8-bb6e-0d7cc843dc60": {"doc_hash": "c996cf787212e364d5453bae56a124423e68c197d413f14262428790b4b89b5d"}, "304663c4-882b-45f2-b1f6-d2798ee5a563": {"doc_hash": "cf94ec26256b214c3eca45f536369a7a93571081a075075e6301dd0401ddf1ad"}, "63165103-14a0-45e8-aea7-675e6a1b726f": {"doc_hash": "04da4a72df378400f0585d0dcd2283eb626536b3e53ed37a78ab161a97ad8fc3"}, "c5393fff-1ed0-4c4b-a879-b6611cd9c8ee": {"doc_hash": "fc422f2622f1572e3cc1463ee11fc36567016a2de77903f2549de3dea9444085"}, "9254db6a-6a6b-4b61-8125-626fabcf1596": {"doc_hash": "4efeb21f3486aaed1f70a908721616ed324ba7c953748ff96538a7c446a63b71"}, "2a88c970-74ef-444a-84c3-5f06b9c8288d": {"doc_hash": "90405bd72bae85d3f315990d219b5197ca9ad75db5e8135cbe695e03863a30a8"}, "31dc84f6-3ea1-4454-ac69-a072260125c7": {"doc_hash": "12795ad6286e97675b3b8160f0a4a15adf4fe706b82dec50e4d38e480118cc20"}, "fb50424d-e2dc-4a80-9fe0-f1962d0ea8cf": {"doc_hash": "08ab410894418c3655245cf1faf02b36c8430c8fa31fab4adcd5f9c0aef8a019"}, "f90a6c30-5bee-47fb-8d20-d3464b744e07": {"doc_hash": "3cb85b9823d3d8296d1e9cf12c722e336cbbac5d798a36f674f217d3ea721065"}, "ccd5cb81-46a6-4ce3-9a25-ff0ef175e32b": {"doc_hash": "a8dc6a44002508cff6e418734f984b5f9e2a7d41a6cf224b8d35e9d480ed2c6c"}, "2fbc48b7-8884-4606-847a-1b7772d6cc30": {"doc_hash": "e02438f8fa13b022bbeaf9df6f91b2ae2d3dd3253d6f6b77b7149addf379b3bf"}, "3d528bf3-6ca9-44d8-a96a-499f92505218": {"doc_hash": "4e12e461933ca64f77f7cf0107ca33e98a7ccefe1bee033d243c44a6bb80db6d"}, "e8655706-c5b1-407f-8a98-d5b7ac29e54c": {"doc_hash": "710d664a0e33a20d2cc31be6cfe0062163a226ca2ce7c7fc7b8ea3e2e05bfbd2"}, "e79da3e8-c089-4d46-83a9-3d6d11bb9bae": {"doc_hash": "9b534cb41af64679ff05552587f3da8d74a0e9eeaf0b1e7f060dfd5aa5e0c9de"}, "847be3d6-fd59-4397-9484-7ccf6da031bb": {"doc_hash": "bfb8fd91f33159a9981d3f93bcfa99da444ec2e20906abfb05a022dfd7752fe0"}, "bfe5fbbb-99e9-4b9d-a6b9-397c7e2c853b": {"doc_hash": "5e199ee1cdb75b8bb0274a0179f99affddb86adca3ed1284b0758a8036aadf21"}, "6eaadc21-af5a-4c43-80a9-62b866c686a4": {"doc_hash": "cc0467850dd4d0d34178dda7c4465d2427e65739ba311613264768609f00e0d6"}, "b6e07977-2079-4df3-95ac-4a99a1f2665c": {"doc_hash": "08f4885bebc518815c09ce7eaa88f14c92257ac24bc26d61123abb92e51dc5aa"}, "39e728ad-0d5d-4ecc-912c-114d1339ac34": {"doc_hash": "bdf1bede42fa3500c6d7e63f3f1d9b4625efd3ba69ea98ef3126858a006727cf"}, "57974253-9413-4595-a6ca-4deb47830abd": {"doc_hash": "24327da8c601a8a656fa1f39cbe2bc467e2a96bc6f798e135565fc3f960e5de5"}, "60ac34cf-5d0b-4401-a4d4-62970ea9ccc7": {"doc_hash": "e680f18f0452555efff2c7d8f1476c8c157581435a9761b216e145e23c465fc5"}, "9561ff46-2af2-4aef-aaa5-f41590568924": {"doc_hash": "d741f8f579a9962285cd3dfe08ea34722463fc959ecf9664f7225b76f5446e0d"}, "06750efa-f508-4023-8e00-e516411849cd": {"doc_hash": "9711c1bf026ed99812cf3bbb95cfba08ff1d78b59086429ec81167cf563a2fcd"}, "af97a169-5f69-4b9e-b3f3-f51c1e2cdff1": {"doc_hash": "89f81d940d1d766bb964d86793e0f279715639765d7c2793fe2d0ee2a86ea9a1"}, "44ed80c9-987f-4af5-a7c5-afd220fe7481": {"doc_hash": "a62eb1e43b744ae0c0507c6c4b804917959d3b31e129e7a69dfa8a93917eb600"}, "fd08b94c-53cf-46c3-8d1e-a5acb9b69ed3": {"doc_hash": "a7ebc159fea5a2816631a862b29594ba58f4a553b49d14cb303873d52b3385a2"}, "cfb71187-a633-40ad-bb5d-583d8a479a65": {"doc_hash": "c9f7a42b82a5647a599756edf91f217cee844029b4f1951fe9a85573704e253d"}, "7c1d7cee-33b1-423e-b59f-022bae65c6e6": {"doc_hash": "52b1b7847c24a3d651b63b46c151af2e68ac633ca6faa225096382999ac2e58d"}, "300fd77f-c1b3-41ed-a3f4-c3a04c11bbdc": {"doc_hash": "9964a13ad75e05d174ce7a0bb450e9a445a42c3e749bd259eb0f9bfd4c6b43bc"}, "c2f0b016-badd-4ed6-9f10-54d0f7d2be45": {"doc_hash": "61e52840658318b6587f0deaa771b00c2186ca7622eba3fd71bf284ddb607586"}, "edf510ba-77c9-4982-a7c2-0542c23fc9e4": {"doc_hash": "ef8ef5ad4880c46016b73d1f63256f22b047ff48b6ea4f30aa9cd8c41d58bcd8"}, "38860cdc-85a9-4b8a-8ac3-91ab8c954468": {"doc_hash": "8f0a9f2ef30275c0f83be8a5b9373a4fca455a9142bfc4ba23a648296d7ea0a6"}, "3e7963bb-28e8-48db-855e-9660e11fcf14": {"doc_hash": "6ed45c3bb1f25f67918666507f75adff1a53d61f342a8945442f6dda970cad7e"}, "6f9a237d-6206-4c2b-a5b1-ebbbffbe3a34": {"doc_hash": "d2d5a5611da2fd2ca6dd12ee6654379224668f81866a7da8e603e64c85e37239"}, "a6a0e395-f36c-42bd-8600-a9990fcfd488": {"doc_hash": "a2319951452b684a425c6ebce1449c12669e704e94408695bfba58c1363672fc"}, "5f15be51-a119-46b9-a174-ac5c9030915a": {"doc_hash": "762376d71b5250d587cc101f74517f0954302b400aef38b32a2441e77b1ef420"}, "8b6a62ca-f15d-4c3e-9ac8-a418e9cebc6f": {"doc_hash": "9d64723a12c97322e3b182c19d30c07acbc11cba04f9f77fcbb4eb6ac3b4099f"}, "9b892026-c13c-4acd-84f9-435e34712be4": {"doc_hash": "8fd7566f2c48194bdcf3c7c18777e8f3848efdb331de76b578fe1842e761eea1"}, "89dcea20-20e3-4ca7-b886-9b5cf3a4b8b4": {"doc_hash": "f2ceb3c2eb8441fe1b0540191cc91eae10d0450e6a6869fab1495632142fe11e"}, "ddfe7b29-c37e-47d4-8d53-71756a6b1b83": {"doc_hash": "d562d41479fc7759cc770d489d67f367ad0c71ec23f0a6d859bc9c767791f77c"}, "d4c2d851-cae8-4d8f-aa47-20bca1fb197b": {"doc_hash": "7e37c77047d69ebf45ce2993cc47e1f7e128441b259378b1d8219e478462ecfb"}}}